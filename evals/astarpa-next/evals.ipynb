{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A*PA-next evals\n",
    "\n",
    "This notebook contains the latest evals for the A*PA project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='once', category=UserWarning)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data reading and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsize=10\n",
    "markersize=4\n",
    "linewidth = 0.75\n",
    "\n",
    "def column_display_name(col):\n",
    "    d = {\n",
    "        \"divergence\": \"Divergence\",\n",
    "        \"runtime\": \"Runtime per alignment [s]\",\n",
    "        \"runtime_capped\": \"Runtime per alignment [s]\",\n",
    "        \"s_per_pair\": \"Avg. runtime per alignment [s]\",\n",
    "        \"s_per_pair_capped\": \"Avg. runtime per alignment [s]\",\n",
    "        \"length\": \"Sequence length [bp]\",\n",
    "        \"band\": \"Equivalent band\",\n",
    "        \"algo_key\": \"algorithm\",\n",
    "        \"algo_pretty\": \" \",\n",
    "    }\n",
    "    if col in d:\n",
    "        return d[col]\n",
    "    return col\n",
    "\n",
    "dataset_pretty = {'ont-ul-500k': 'ONT reads', 'ont-minion-ul-500k': 'ONT reads + genetic variation'}\n",
    "dataset_order = list(dataset_pretty.keys())\n",
    "\n",
    "\n",
    "# Line style:\n",
    "# - slow (no pruning): dotted\n",
    "# - normal: solid\n",
    "# - diagonal-transition: dashed\n",
    "# Colours:\n",
    "# edlib/wfa ('extern'): blue/purple\n",
    "# sh/csh/gcsh: orange -> brown -> green gradient\n",
    "# noprune/normal/dt: 60% -> 70% -> 85% saturation\n",
    "colors = {'dijkstra': '#786061', 'sh': \"#e87146\", 'csh': \"#8c662a\", 'gcsh': \"#257d26\"}\n",
    "dashed = (0, (5, 5))\n",
    "dotted = (0, (1, 4))\n",
    "algorithm_styles = {\n",
    "    \"edlib\": (\"#DE4AFF\", dashed, 'Edlib'),\n",
    "    \"biwfa\": (\"#625AFF\", '-', 'BiWFA'),\n",
    "    'blockaligner': ('#0000ff', '.', 'Block\\nAligner\\n(128,1024)'),\n",
    "    \"dijkstra\": (colors['dijkstra'], dashed, 'Dijkstra'),\n",
    "    \"sh-noprune\": (colors['sh'], dotted, 'SH (no prune)'),\n",
    "    \"sh\": (colors['sh'], dashed, 'SH'),\n",
    "    \"csh\": (colors['csh'], dashed, 'CSH'),\n",
    "    \"gcsh\": (colors['gcsh'], dashed, 'GCSH'),\n",
    "    \"dijkstra-dt\": (colors['dijkstra'], '-', 'Dijkstra+DT'),\n",
    "    \"sh-dt\": ('#e35522', '-', 'SH+DT'),\n",
    "    \"csh-dt\": ('#875a12', '-', 'CSH+DT'),\n",
    "    \"gcsh-dt\": ('#0f7a10', '-', 'GCSH+DT'),\n",
    "    'astarpa': ('#0f7a10', '-', 'GCSH+DT'),\n",
    "    'astarnw': ('#000000', '.', 'A*NW'),\n",
    "    'astarnw-gapgap': ('#bb0000', '.', 'A*NW\\n+gapgap'),\n",
    "    'astarnw-gapdist': ('#ee0000', '.', '\\n\\n+gapdist'),\n",
    "    'astarnw-blocks': ('#ff0000', '.', '\\n\\n\\n+blocks'),\n",
    "    'astarnw-sparse_mem': ('#ff6600', '.', '\\n+sparse mem'),\n",
    "    'astarnw-new-profile': ('#ffcc00', '.', '\\n\\n+bit-profile'),\n",
    "    'astarnw-trace': ('#aacc00', '.', '\\n\\n\\n+new trace'),\n",
    "    'astarnw-local-pruning-5': ('#77cc00', '.', '+local\\npruning'),\n",
    "    'astarnw-prune': ('#00cc77', '.', '\\n\\n+pruning'),\n",
    "    'astarnw-matches': ('#00aaaa', '.', '\\n\\n\\n+match filter'),\n",
    "    'astarnw-matches2': ('#0099ee', '.', '\\n+faster LP'),\n",
    "    'astarnw-dt-trace': ('#0066ff', '.', '\\n\\n+DT trace'),\n",
    "    'astarnw-k12': ('#0033ff', '.', 'k: 12\\n(from 15)'),\n",
    "    'astarnw-local-doubling': ('#3300ff', '.', '\\n\\n+local\\ndoubling'),\n",
    "    'astarnw-k12-new': ('#0033ff', '.', 'k: 12\\n(from 15)\\nNEW'),\n",
    "    'astarnw-local-doubling-new': ('#3300ff', '.', '\\n\\n+local\\ndoubling\\nNEW'),\n",
    "}\n",
    "algorithm_order = list(algorithm_styles.keys())\n",
    "palette = {k: v[0] for k, v in algorithm_styles.items()}\n",
    "\n",
    "def get_algorithm_key(row):\n",
    "    name = row['algo_name']\n",
    "    if name == 'Edlib': return 'edlib'\n",
    "    if name == 'Wfa':\n",
    "        if row['job_algo_Wfa_memorymodel'] == 'MemoryUltraLow':\n",
    "            return 'biwfa'\n",
    "        else:\n",
    "            return 'wfa'\n",
    "    if name == 'BlockAligner':\n",
    "        return 'blockaligner'\n",
    "    if name == 'AstarPa':\n",
    "        t = row['job_algo_AstarPa_heuristic_type']\n",
    "        r = row['job_algo_AstarPa_heuristic_type']\n",
    "        dt = row['job_algo_AstarPa_diagonaltransition']\n",
    "        prune = row['job_algo_AstarPa_heuristic_prune'] if 'job_algo_AstarPa_heuristic_prune' in row else 'Both'\n",
    "        if t == 'None':\n",
    "            key = 'dijkstra'\n",
    "        else:\n",
    "            key = t.lower()\n",
    "        if t != 'None' and prune == 'None':\n",
    "            key += '-noprune'\n",
    "        if dt:\n",
    "            key += '-dt'\n",
    "        return key\n",
    "    if name == 'AstarNW':\n",
    "        key = 'astarnw'\n",
    "        name = row.job_algo_AstarNW_name\n",
    "        if name:\n",
    "            return f'{key}-{name}'\n",
    "        if row.job_algo_AstarNW_front_Bit_sparse:\n",
    "            key += '-sparse'\n",
    "        if row.job_algo_AstarNW_front_Bit_simd:\n",
    "            key += '-simd'\n",
    "        if row.job_algo_AstarNW_sparsehcalls:\n",
    "            key += '-h'\n",
    "        return key\n",
    "    return 'unknown'\n",
    "\n",
    "# Returns display name, color, and style for an algorithm\n",
    "def algorithm_display(row, split):\n",
    "    (c, l, n) = algorithm_styles[row['algo_key']]\n",
    "    if 'r' in split:\n",
    "        if row.r:\n",
    "            n += f' (r={row.r})'\n",
    "    return (c, l, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results(path):\n",
    "    # - Read a json file\n",
    "    # - Rename json fields from a_b to a-b\n",
    "    # - Flatten into dataframe\n",
    "    # - Flatten algorithm params into a few fields:\n",
    "    #   - algo_name: the type of algorithm\n",
    "    #   - algo_full: the json-string of algorithm parameters\n",
    "    # - Rename and compute some common columns:\n",
    "    #   - error-rate\n",
    "    #   - length\n",
    "    #   - s_per_pair\n",
    "    #   - p_correct\n",
    "    \n",
    "    json_path = Path(path)\n",
    "    data = json.loads(json_path.read_text())\n",
    "    \n",
    "    # Remove underscores from all keys\n",
    "    def remove_underscores(o):\n",
    "        if isinstance(o, list):\n",
    "            return [remove_underscores(v) for v in o]\n",
    "        if isinstance(o, dict):\n",
    "            return {k.replace('_', ''): remove_underscores(v) for k, v in o.items()}\n",
    "        return o\n",
    "    \n",
    "    data = remove_underscores(data)\n",
    "\n",
    "    # Clean up algo columns\n",
    "    for x in data:\n",
    "        name = list(x['job']['algo'].keys())[0]\n",
    "        obj = x['job']['algo']\n",
    "        obj['name'] = name\n",
    "        x['algo_name'] = name\n",
    "        x['algo_full'] = json.dumps(obj)\n",
    "        #del x['job']['algo']\n",
    "        if 'Ok' in x['output']:\n",
    "            del x['output']['Ok']['costs']\n",
    "\n",
    "    # Flatten the js\n",
    "    df = pd.json_normalize(data, sep='_')\n",
    "    df['algo_key'] = df.apply(get_algorithm_key, axis=1)\n",
    "    df['algo_pretty'] = df['algo_key'].map(lambda key: algorithm_styles[key][2])\n",
    "    \n",
    "    # Convenience renaming\n",
    "    df = df.rename({'job_dataset_Generated_length': 'length',\n",
    "                    'job_dataset_Generated_errorrate': 'errorrate',\n",
    "                    'job_timelimit': 'timelimit',\n",
    "                    'output_Ok_pcorrect': 'pcorrect',\n",
    "                    'output_Ok_measured_runtime': 'runtime',\n",
    "                    'output_Ok_measured_memory': 'memory',\n",
    "                    'stats_divergence_mean': 'divergence',\n",
    "                    'job_algo_AstarPa_diagonaltransition': 'dt',\n",
    "                    'job_algo_AstarPa_heuristic_prune': 'prune',\n",
    "                    'job_algo_AstarPa_heuristic_r': 'r',\n",
    "                    #'job_algo_AstarNW_heuristic_r': 'r',\n",
    "                   }, axis='columns')\n",
    "    \n",
    "    # Order rows\n",
    "    df['algo_ord'] = df['algo_key'].map(lambda key: algorithm_order.index(key))\n",
    "    df.sort_values(by='algo_ord', inplace=True, kind = 'stable')\n",
    "    if 'length' in df.columns:\n",
    "        df.sort_values(by='length', inplace=True, kind = 'stable')\n",
    "    if 'errorrate' in df.columns:\n",
    "        df.sort_values(by='errorrate', inplace=True, kind = 'stable')\n",
    "    # Order by dataset\n",
    "    if 'job_dataset_File' in df.columns and df.job_dataset_File.notna().all():\n",
    "        df['dataset'] = df['job_dataset_File'].map(lambda f: Path(f).parent.name)\n",
    "        df['dataset_ord'] = df['dataset'].map(lambda key: dataset_order.index(key) if key in dataset_order else key)\n",
    "        df.sort_values(by='dataset_ord', inplace=True, kind = 'stable')\n",
    "    \n",
    "    # Computed columns\n",
    "    df['costmodel'] = df.apply(lambda row: (row['job_costs_sub'], row['job_costs_open'], row['job_costs_extend']), axis=1)\n",
    "    df['s_per_pair'] = df['runtime'] / df['stats_seqpairs']\n",
    "    df['timelimit_per_pair'] = df['timelimit'] / df['stats_seqpairs']\n",
    "    if 'length' in df.columns and 'output_Ok_stats_expanded' in df.columns:\n",
    "        df['band'] = df['output_Ok_stats_expanded'] / (df['stats_seqpairs']* df['length'])\n",
    "\n",
    "    def runtime_capped(row):\n",
    "        if not math.isnan(row['runtime']):\n",
    "            return row['runtime']\n",
    "        if row['output_Err'] == 'Timeout':\n",
    "            return row['timelimit']\n",
    "        return row['timelimit']*1.1\n",
    "    df['runtime_capped'] = df.apply(runtime_capped, axis = 1)\n",
    "    df['s_per_pair_capped'] = df['runtime_capped'] / df['stats_seqpairs']\n",
    "    \n",
    "    df['editdistance'] = df['stats_insertions'] + df['stats_deletions'] + df['stats_substitutions']\n",
    "    \n",
    "    # Some specific fixes\n",
    "    df = df.fillna({'r': 0}, downcast='infer')\n",
    "    \n",
    "    # Remove unsupported algos\n",
    "    if 'output_Err' in df.columns:\n",
    "        df = df[df.output_Err != 'Unsupported']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The one plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df,\n",
    "         name='',\n",
    "         file=None,\n",
    "         x='length',\n",
    "         y='s_per_pair',\n",
    "         # Column to use for hue and style.\n",
    "         # Always change both at the same time!\n",
    "         hue='algo_key',\n",
    "         style='r',\n",
    "         # column to use for marker size\n",
    "         size=None,\n",
    "         # Logarithmic axes by default\n",
    "         xlog=True,\n",
    "         ylog=True,\n",
    "         ylim=None,\n",
    "         # alph\n",
    "         alpha=1.0,\n",
    "         # Use line instead of scatter plot?\n",
    "         connect=False,\n",
    "         # Draw a cone from the given filter and x\n",
    "         cone=None,\n",
    "         cone_x=3*10**4,\n",
    "         fit=False,\n",
    "         line_labels=False,\n",
    "         categorical=False,\n",
    "         ax=None,\n",
    "         width=None,\n",
    "         height=None,\n",
    "         png=False\n",
    "        ):\n",
    "    \n",
    "    if df[y].isna().all():\n",
    "        print(f\"All values of {y} are nan.\")\n",
    "        return\n",
    "    \n",
    "    df = df[df[y].notnull()]\n",
    "    assert not df.empty\n",
    "    \n",
    "    # We group data by this set of keys.\n",
    "    split = [hue, style]\n",
    "    \n",
    "    # Remove 'r' from the split if not both r=1 and r=2 are present,\n",
    "    # to prevent redundant (r=1) in plots.\n",
    "    if 'r' in split and 'r' in df.columns:\n",
    "        if not (1 in df.r.values and 2 in df.r.values):\n",
    "            split.remove('r')\n",
    "    \n",
    "    # Group the data into datapoints per line\n",
    "    groups = df.groupby(split, sort=False)\n",
    "    \n",
    "    # Not sure if needed actually.\n",
    "    sns.reset_defaults()\n",
    "    sns.set_context(None) # 'paper', 'notebook'\n",
    "    \n",
    "    # Set up the figure if not provided.\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(width if width else 3, height if height else 2, forward=True)\n",
    "        hasax = False\n",
    "    else:\n",
    "        hasax = True\n",
    "\n",
    "    \n",
    "    # Set log scales\n",
    "    ax.set(xscale='log' if xlog else 'linear', yscale='log' if ylog else 'linear')\n",
    "    \n",
    "    # limit number of ticks\n",
    "    if ylog:\n",
    "        ax.locator_params(axis='y', numticks=6)\n",
    "    else:\n",
    "        ax.locator_params(axis='y', nbins=6)\n",
    "    \n",
    "    \n",
    "    # PLOTTING\n",
    "    \n",
    "    if not categorical:\n",
    "        # Show a scatterplot of points.\n",
    "        # Each group is plotted separately for more control over its style.\n",
    "        for k, group in groups:\n",
    "            first_row = group.iloc[0]\n",
    "            color, linestyle, grouplabel = algorithm_display(first_row, split)\n",
    "\n",
    "            ax.plot(x,\n",
    "                    y,\n",
    "                    data=group.sort_values(by=x),\n",
    "                    color=color,\n",
    "                    linestyle=linestyle if connect else 'None',\n",
    "                    marker='o',\n",
    "                    alpha=alpha,\n",
    "                    dash_capstyle = 'round',\n",
    "                    label=grouplabel,\n",
    "                    zorder=2,\n",
    "                    markersize=markersize,\n",
    "                    linewidth=linewidth\n",
    "                   )\n",
    "    if categorical:\n",
    "        # Overlay a boxplot and swarmplot on top of each other\n",
    "        sns.swarmplot(data=df,\n",
    "                        x=x,\n",
    "                        y=y,\n",
    "                        hue=hue,\n",
    "                        palette=palette,\n",
    "                        ax=ax,\n",
    "                        size=3,\n",
    "                        linewidth=0,\n",
    "                        edgecolor='gray',\n",
    "                        zorder=9,\n",
    "                        dodge=False,\n",
    "        )\n",
    "        sns.boxplot(data=df,\n",
    "                    x=x,\n",
    "                    y=y,\n",
    "                    zorder=10,\n",
    "                    ax=ax,\n",
    "                    boxprops={'facecolor':'None'},\n",
    "                    showfliers=False,\n",
    "                    linewidth=linewidth,\n",
    "                   )\n",
    "    \n",
    "    # TEXT\n",
    "    \n",
    "    # Title\n",
    "    if name:\n",
    "        ax.set_title(name, y=1.05)\n",
    "    \n",
    "    # Remove legend\n",
    "    ax.legend().remove()\n",
    "    \n",
    "    # BACKGROUND\n",
    "    ax.set_facecolor(\"#F8F8F8\")\n",
    "    ax.set_axisbelow(True) \n",
    "    ax.grid(False)\n",
    "    ax.grid(True, axis=\"y\", which=\"major\", color=\"white\", alpha=1, zorder=0)\n",
    "    \n",
    "    \n",
    "    # AXES\n",
    "    \n",
    "    # Labels\n",
    "    ax.set_xlabel(column_display_name(x))  # weight='bold',\n",
    "    ax.set_ylabel(column_display_name(y), rotation=0, ha=\"left\")\n",
    "    ax.yaxis.set_label_coords(-0.10, 1.00)\n",
    "    \n",
    "    # Limits\n",
    "    x_margin = 1.5\n",
    "    y_margin = 3\n",
    "    if xlog:\n",
    "        #xs = df[df[x] > 0][x]\n",
    "        ax.set_xlim(df[x].min() / x_margin, df[x].max() * x_margin)\n",
    "\n",
    "    if ylog:\n",
    "        ax.set_ylim(df[y].min() / y_margin, df[y].max() * y_margin)\n",
    "    \n",
    "    # Start linear scales at 0.\n",
    "    if not xlog and not categorical and x != 'job_costs_open':\n",
    "        ax.set(xlim=(0,None))\n",
    "    if not ylog:\n",
    "        ax.set(ylim=(0,None))\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim[0], ylim[1])\n",
    " \n",
    "    \n",
    "    # Show bottom spine, and left spine when xlog=false\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(True)\n",
    "    ax.spines['left'].set_visible(not xlog and not categorical)\n",
    "    \n",
    "    # Format % scales.\n",
    "    if x in ['errorrate', 'divergence']:\n",
    "        ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0, decimals=0))\n",
    "    \n",
    "    # Show major ticks\n",
    "    ax.tick_params(\n",
    "        axis=\"both\",\n",
    "        which=\"major\",\n",
    "        bottom=True,\n",
    "        top=False,\n",
    "        left=True,\n",
    "        right=False,\n",
    "    )\n",
    "    # No minor ticks\n",
    "    ax.tick_params(\n",
    "        axis=\"both\",\n",
    "        which=\"minor\",\n",
    "        bottom=False,\n",
    "        top=False,\n",
    "        left=False,\n",
    "        right=False,\n",
    "        labelbottom=False,  # labels along the bottom edge are off\n",
    "    )\n",
    "    # Do show minor ticks for small log ranges\n",
    "    if ylog:\n",
    "         ax.tick_params(axis=\"y\", which=\"minor\", left=True)\n",
    "    \n",
    "    \n",
    "    # CONE\n",
    "    # Fills the region between x**1 and x**2\n",
    "    if cone:\n",
    "        x0 = cone_x\n",
    "        x_max = x_margin * df[x].max()\n",
    "        x_range = (x0, x_max)\n",
    "        \n",
    "        y0 = df[cone(df) & (df[x] == cone_x)][y].max()\n",
    "        y_lin = (y0, y0 * (x_max / x0) ** 1)\n",
    "        y_quad = (y0, y0 * (x_max / x0) ** 2)\n",
    "        ax.fill_between(x_range, y_lin, y_quad, color=\"grey\", alpha=0.15, zorder=0.4)\n",
    "        \n",
    "    # TIME LIMIT\n",
    "    if y=='runtime_capped' or (y=='s_per_pair_capped' and x != 'length'):\n",
    "        timelimit = df.timelimit.iloc[0]\n",
    "        #assert df[df.runtime.isna()].timelimit.eq(timelimit).all()\n",
    "        # Draw a red line at the timelimit.\n",
    "        ax.axhline(y=timelimit, color=\"red\", linestyle=\"-\", alpha=1, linewidth=0.5)\n",
    "        \n",
    "        # Modify/add the timelimit ticklabel with TL=\n",
    "        if False:\n",
    "            ylabels = [x for x in ax.get_yticklabels()]\n",
    "            found = False\n",
    "            for i, l in enumerate(ylabels):\n",
    "                if l.get_position()[1] == timelimit:\n",
    "                    ylabels[i] = \"TL=\" + ylabels[i].get_text()\n",
    "                    found = True\n",
    "            if found:\n",
    "                ax.set_yticklabels(ylabels)\n",
    "            else:\n",
    "                yticks = list(ax.get_yticks())\n",
    "                ylabels = list(ax.get_yticklabels())\n",
    "                yticks.append(timelimit)\n",
    "                ylabels.append(\"TLE\")\n",
    "                ax.set_yticks(yticks)\n",
    "                try:\n",
    "                    ax.set_yticklabels(ylabels)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                finally:\n",
    "                    pass\n",
    "            \n",
    "    # POLY FIT\n",
    "\n",
    "    def angle(slope):\n",
    "        x_min, x_max = ax.get_xlim()\n",
    "        y_min, y_max = ax.get_ylim()\n",
    "        bbox = ax.get_window_extent()\n",
    "        x_sz = bbox.width\n",
    "        y_sz = bbox.height\n",
    "        x_factor = x_sz / (np.log10(x_max) - np.log10(x_min) if xlog else x_max - x_min)\n",
    "        y_factor = y_sz / (np.log10(y_max) - np.log10(y_min) if ylog else y_max - y_min) \n",
    "        slope = slope * y_factor / x_factor\n",
    "        return math.atan(slope)*180/math.pi\n",
    "    \n",
    "    if fit:\n",
    "        assert x=='length' and xlog and ylog, \"Polynomial fits only work in log-log plots with x=length\"\n",
    "        for k, group in groups:\n",
    "            first_row = group.iloc[0]\n",
    "            color, linestyle, grouplabel = algorithm_display(first_row, split)\n",
    "            fit_label = grouplabel\n",
    "            \n",
    "            filtered = group[group.runtime.notnull()]\n",
    "            ps = filtered[[x,y]].dropna()\n",
    "            xmin, xmax = filtered[x].min(), filtered[x].max()\n",
    "            if len(ps) > 1:\n",
    "                fit = np.polyfit(np.log(ps[x]), np.log(ps[y]), 1)\n",
    "                f = lambda x: x**fit[0] * np.exp(fit[1])\n",
    "                # Extra {{ and }} are for the math-mode superscript\n",
    "                fit_label = f\"{grouplabel} $\\sim n^{{{fit[0]:0.2f}}}$\"\n",
    "\n",
    "                ymin, ymax = f(xmin), f(xmax)\n",
    "                # line from xmin to xmax (use plt.axline for infinite line)\n",
    "                ax.plot([xmin, xmax], [ymin, ymax], color=color, linestyle=linestyle, alpha=1, dash_capstyle = 'round', label=grouplabel, zorder=2, linewidth=linewidth)\n",
    "                #print(f'Exponent for {k}: {fit[0]:0.2f}')\n",
    "\n",
    "            ax.text(\n",
    "                xmax,\n",
    "                min(ymax, ax.get_ylim()[1]),\n",
    "                fit_label,\n",
    "                color=color,\n",
    "                ha=\"right\",\n",
    "                va=\"bottom\",\n",
    "                size=labelsize,\n",
    "                alpha=1,\n",
    "                rotation=angle(fit[0]),\n",
    "                rotation_mode='anchor',\n",
    "            )\n",
    "    if line_labels:\n",
    "        # If no legend and no fits are shown, show manual labels instead\n",
    "        for split_key, group in groups:\n",
    "            first_row = group.iloc[0]\n",
    "            color, linestyle, grouplabel = algorithm_display(first_row, split)\n",
    "            max_idx = group[x].idxmax()\n",
    "            label_x = group[x][max_idx]\n",
    "            label_y = min(group[y][max_idx], ax.get_ylim()[1])\n",
    "            key = split_key[0] if isinstance(split_key, tuple) else split_key\n",
    "            \n",
    "            by_x = group[x].argsort()\n",
    "            last = group.iloc[by_x.iloc[-1]]\n",
    "            before = group.iloc[by_x.iloc[-3]]\n",
    "            slope = (last[y] - before[y])/(last[x] - before[x])\n",
    "            ax.text(\n",
    "                label_x,\n",
    "                label_y,\n",
    "                grouplabel,\n",
    "                color=color,\n",
    "                ha=\"right\",\n",
    "                va=\"bottom\",\n",
    "                size=labelsize,\n",
    "                alpha=1,\n",
    "                rotation=angle(slope),\n",
    "                rotation_mode='anchor',\n",
    "            )\n",
    "\n",
    "    if not hasax:\n",
    "        if file:\n",
    "            plt.savefig(f\"plots/{file}.pdf\", dpi=300, bbox_inches='tight')\n",
    "            if png:\n",
    "                plt.savefig(f\"plots/{file}.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boxplots on testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "warnings.simplefilter('ignore', category=UserWarning)\n",
    "df = read_results(\"results/real.json\")\n",
    "def boxplot(df, w, **kwargs):\n",
    "    ww=1\n",
    "    datasets = len(df.dataset.unique())\n",
    "    hh = (datasets+ww-1)//ww\n",
    "    w *= ww\n",
    "    h = 3.7 * hh\n",
    "    fig, axs = plt.subplots(hh, ww, figsize=(w, h))\n",
    "    if not isinstance(axs, np.ndarray):\n",
    "        axs = [axs]\n",
    "    if isinstance(axs[0], np.ndarray):\n",
    "        axs = [x for col in zip(*axs) for x in col]\n",
    "    for (k, g), ax in zip(df.groupby('dataset'),axs):\n",
    "        plot(g, x='algo_pretty', y='runtime_capped', xlog=False, ylog=True, categorical=True, ylim=(0.01, 15), ax=ax, **kwargs)\n",
    "        ax.tick_params(axis=\"y\", which=\"both\", right=True)\n",
    "        ax.grid(True, axis=\"y\", which=\"major\", color=\"black\", alpha=.5, zorder=0, lw=0.5)\n",
    "        ax.grid(True, axis=\"y\", which=\"minor\", color=\"black\", alpha=.1, zorder=0, lw=0.5)\n",
    "        \n",
    "        ax.set_xlabel(dataset_pretty.get(k, k))\n",
    "\n",
    "        if False:\n",
    "            print(k)\n",
    "            for (kk, gg) in g.groupby('algo_pretty', sort=False):\n",
    "                qs = [gg.runtime_capped.quantile(q) for q in [0, 0.25, 0.5, 0.75, 1]]\n",
    "                name = kk.strip().replace(\"\\n\", \" \")\n",
    "                print(f'{name:20}: {qs[0]:0.3f} {qs[1]:0.3f} {qs[2]:0.3f} {qs[3]:0.3f} {qs[4]:0.3f}')\n",
    "    \n",
    "    fig.subplots_adjust(wspace=.05, hspace=0.6)\n",
    "    plt.show()\n",
    "boxplot(df, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_results(\"results/real.json\")\n",
    "df.memory = (df.memory/1000000)\n",
    "df['capped_memory'] = df.memory.fillna(1000000)\n",
    "#df = df[df.algo_key.isin(['edlib', 'biwfa', 'gcsh-dt', 'astarnw', 'astarnw-sparse'])]\n",
    "table = df.pivot_table(index='algo_pretty', columns=['dataset'], values=['capped_memory', 'memory'], aggfunc={'capped_memory': np.median, 'memory': np.max}, sort=False).round(0).astype('int')\n",
    "table =table.rename({'capped_memory': 'Median', 'memory': 'Max'}, axis='columns')\n",
    "table = table.swaplevel(axis=1)\n",
    "table.sort_index(axis=1, level=0, inplace=True, kind='stable', ascending=False)\n",
    "display(table)\n",
    "#print(table.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check: CPU frequency\n",
    "Make sure that the CPU frequency is consistent over all experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_results(\"results/real.json\")\n",
    "df = df.rename({'output_Ok_measured_cpufreqstart': 'freqstart','output_Ok_measured_cpufreqend': 'freqend'}, axis='columns')\n",
    "for c in ['freqstart', 'freqend']:\n",
    "    print(df[c].min(), df[c].max())\n",
    "    assert df[c].min() > 2550\n",
    "    assert df[c].max() < 2650"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "name": "evals.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
