{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faca2249-cc25-467c-b8a9-a6d69f0ea4cb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# A*PA2 evals\n",
    "\n",
    "This notebook contains the latest evals for A*PA2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "489905a3-ca48-4df3-8656-bdbadf29d6cf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='once', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.lines as mlines\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "99be5690-4536-417e-a8af-94245b25903b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499567c3-3db5-4629-b782-9cb2a39cef3b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Data reading and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "13e7b1a8-0eee-4cd5-8e7f-fbbaca0ddf69",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "labelsize=10\n",
    "markersize=4\n",
    "linewidth = 0.75\n",
    "\n",
    "def column_display_name(col):\n",
    "    d = {\n",
    "        \"divergence\": \"Divergence\",\n",
    "        \"runtime\": \"Runtime per alignment [s]\",\n",
    "        \"runtime_capped\": \"Runtime per alignment [s]\",\n",
    "        \"s_per_pair\": \"Avg. runtime per alignment [s]\",\n",
    "        \"s_per_pair_capped\": \"Avg. runtime per alignment [s]\",\n",
    "        \"length\": \"Sequence length [bp]\",\n",
    "        \"band\": \"Equivalent band\",\n",
    "        \"algo_key\": \"algorithm\",\n",
    "        \"algo_pretty\": \" \",\n",
    "    }\n",
    "    if col in d:\n",
    "        return d[col]\n",
    "    return col\n",
    "\n",
    "dataset_pretty = {\n",
    "    'sars-cov-2': 'SARS-CoV-2 pairs',\n",
    "    'ont-1k': '1kbp ONT reads',\n",
    "    # 'ont-10k': '10kbp ONT reads',\n",
    "    'ont-50k': '10kbp ONT reads',\n",
    "    'ont-500k': '>500kbp ONT reads',\n",
    "    'ont-500k-genvar': '>500kbp ONT reads + gen.var.',\n",
    "    'bam2seq_10kto20k': 'BAM 10k',\n",
    "    'overlap_10kto20k': 'overlap 10k',\n",
    "    'bam2seq_100kto200k': 'BAM 100k',\n",
    "    'overlap_100kto200k': 'overlap 100k',\n",
    "    'bam2seq_unrestricted': 'BAM',\n",
    "    'overlap_unrestricted': 'overlap',\n",
    "}\n",
    "dataset_order = list(dataset_pretty.keys())\n",
    "def dataset_key(key):\n",
    "    return (dataset_order.index(key) if key in dataset_order else 99, key) \n",
    "\n",
    "\n",
    "# Line style:\n",
    "# - slow (no pruning): dotted\n",
    "# - normal: solid\n",
    "# - diagonal-transition: dashed\n",
    "# Colours:\n",
    "# edlib/wfa ('extern'): blue/purple\n",
    "# sh/csh/gcsh: orange -> brown -> green gradient\n",
    "# noprune/normal/dt: 60% -> 70% -> 85% saturation\n",
    "colors = {'dijkstra': '#786061', 'sh': \"#e87146\", 'csh': \"#8c662a\", 'gcsh': \"#257d26\"}\n",
    "dashed = (0, (5, 5))\n",
    "dotted = (0, (1, 4))\n",
    "algorithm_styles = {\n",
    "    \"edlib\": (\"#DE4AFF\", '-', 'Edlib'),\n",
    "    \"biwfa\": (\"#625AFF\", '-', 'BiWFA'),\n",
    "    'astarpa': ('#0f7a10', '-', 'A*PA'),\n",
    "    'astarpa-r1': ('#0f7a10', '-', 'A*PA\\n(r=1)'),\n",
    "    'astarpa-preprune': ('#0f7a10', '-', '+PP'),\n",
    "\n",
    "\n",
    "    \"wfa-adaptive\": (\"#44A\", '-', 'WFA Adaptive'),\n",
    "    \"blockaligner\": (\"#884\", '-', 'Block Aligner'),\n",
    "\n",
    "    # Summary\n",
    "    'astarpa2-simple': ('#aa0000', '-', 'A*PA2\\nsimple'),\n",
    "    'astarpa2-full': ('#00aaaa', '-', 'A*PA2\\nfull'),\n",
    "\n",
    "    # Timing\n",
    "    'astarpa2-t_simple': ('#aa0000', '-', 'A*PA2\\nsimple'),\n",
    "    'astarpa2-t_full': ('#00aaaa', '-', 'A*PA2\\nfull'),\n",
    "\n",
    "    # Incremental\n",
    "    'astarpa2-gapgap': ('#aa0000', '-', 'Band\\nDoubling'),\n",
    "    'astarpa2-gapdist': ('#aa0000', '-', '+A*'),\n",
    "    'astarpa2-blocks': ('#aa0000', '-', '+Blocks'),\n",
    "    'astarpa2-simd': ('#aa0000', '-', '+SIMD'),\n",
    "    'astarpa2-ilp': ('#aa0000', '-', '+ILP'),\n",
    "    'astarpa2-dt-trace': ('#aa0000', '-', '+DTT'),\n",
    "    'astarpa2-sparse_h': ('#aa0000', '-', '+Sparse h\\nA*PA2\\nsimple'),\n",
    "    'astarpa2-incrementaldoubling': ('#00aaaa', '-', '+ID'),\n",
    "    'astarpa2-GCSH': ('#00aaaa', '-', '+GCSH'),\n",
    "    'astarpa2-pre-pruning': ('#00aaaa', '-', '+PP\\n'),\n",
    "    'astarpa2-prune': ('#00aaaa', '-', '+Pruning\\nA*PA2\\nfull'),\n",
    "    \n",
    "    # Ablation full\n",
    "    'astarpa2-GCSH-base': ('#00aaaa', '-', 'GCSH\\nbase'),\n",
    "    'astarpa2-noGCSH': ('#00aaaa', '-', '-GCSH\\n+SH'),\n",
    "    'astarpa2-noGCSH-Gap': ('#00aaaa', '-', '-GCSH\\n+Gap-h'),\n",
    "    'astarpa2-noGCSH-GapGap': ('#00aaaa', '-', '-A*'),\n",
    "    'astarpa2-nosimd': ('#00aaaa', '-', '-SIMD'),\n",
    "    'astarpa2-noilp': ('#00aaaa', '-', '-ILP'),\n",
    "    'astarpa2-nodt': ('#00aaaa', '-', '-DTT'),\n",
    "    'astarpa2-nosparseh': ('#00aaaa', '-', '-Sparse h'),\n",
    "    'astarpa2-noid': ('#00aaaa', '-', '-ID'),\n",
    "    'astarpa2-noprune': ('#00aaaa', '-', '-Prune'),\n",
    "    'astarpa2-nopreprune': ('#00aaaa', '-', '-PP'),\n",
    "\n",
    "    # Ablation simple\n",
    "    'astarpa2-simple-base': ('#cc0000', '-', 'A*PA2-simple'),\n",
    "    'astarpa2-simple-gapgap': ('#cc0000', '-', '-A*'),\n",
    "    'astarpa2-simple-nosimd': ('#cc0000', '-', '-SIMD'),\n",
    "    'astarpa2-simple-noilp': ('#cc0000', '-', '-ILP'),\n",
    "    'astarpa2-simple-id': ('#cc0000', '-', '+ID'),\n",
    "    'astarpa2-simple-nosparseh': ('#cc0000', '-', '-Sparse h'),\n",
    "    'astarpa2-simple-nodt': ('#cc0000', '-', '-DTT'),\n",
    "\n",
    "    # Parameters\n",
    "    # heuristic related\n",
    "    'astarpa2-k10': ('#00aaaa', '-', 'k10'),\n",
    "    'astarpa2-k11': ('#00aaaa', '-', 'k11'),\n",
    "    'astarpa2-k13': ('#00aaaa', '-', 'k13'),\n",
    "    'astarpa2-k14': ('#00aaaa', '-', 'k14'),\n",
    "    'astarpa2-p7': ('#00aaaa', '-', 'p7'),\n",
    "    'astarpa2-p28': ('#00aaaa', '-', 'p28'),\n",
    "    # engineering related\n",
    "    'astarpa2-f1.5': ('#00aaaa', '-', 'f1.5'),\n",
    "    'astarpa2-f2.5': ('#00aaaa', '-', 'f2.5'),\n",
    "    'astarpa2-B512': ('#00aaaa', '-', 'B512'),\n",
    "    'astarpa2-B128': ('#00aaaa', '-', 'B128'),\n",
    "    'astarpa2-B64': ('#00aaaa', '-', 'B64'),\n",
    "    'astarpa2-g80': ('#00aaaa', '-', 'g80'),\n",
    "    'astarpa2-g40': ('#00aaaa', '-', 'g40'),\n",
    "    'astarpa2-g20': ('#00aaaa', '-', 'g20'),\n",
    "    'astarpa2-g10': ('#00aaaa', '-', 'g10'),\n",
    "    'astarpa2-x5': ('#00aaaa', '-', 'x5'),\n",
    "    'astarpa2-x10': ('#00aaaa', '-', 'x10'),\n",
    "    'astarpa2-x20': ('#00aaaa', '-', 'x20'),\n",
    "    'astarpa2-x2': ('#00aaaa', '-', 'x2'),\n",
    "    'astarpa2-r2': ('#00aaaa', '-', 'r2'),\n",
    "    \n",
    "\n",
    "    # Simple parameters\n",
    "    # only engineering related\n",
    "    'astarpa2-simple-f1.5': ('#cc0000', '-', 'f1.5'),\n",
    "    'astarpa2-simple-f2.5': ('#cc0000', '-', 'f2.5'),\n",
    "    'astarpa2-simple-B512': ('#cc0000', '-', 'B512'),\n",
    "    'astarpa2-simple-B128': ('#cc0000', '-', 'B128'),\n",
    "    'astarpa2-simple-B64': ('#cc0000', '-', 'B64'),\n",
    "    'astarpa2-simple-g80': ('#cc0000', '-', 'g80'),\n",
    "    'astarpa2-simple-g40': ('#cc0000', '-', 'g40'),\n",
    "    'astarpa2-simple-g20': ('#cc0000', '-', 'g20'),\n",
    "    'astarpa2-simple-g10': ('#cc0000', '-', 'g10'),\n",
    "    'astarpa2-simple-x5': ('#cc0000', '-', 'x5'),\n",
    "    'astarpa2-simple-x10': ('#cc0000', '-', 'x10'),\n",
    "    'astarpa2-simple-x20': ('#cc0000', '-', 'x20'),\n",
    "    'astarpa2-simple-x2': ('#cc0000', '-', 'x2'),\n",
    "\n",
    "    'speedup': ('', '', 'A*PA2 speedup'),\n",
    "\n",
    "}\n",
    "algorithm_order = list(algorithm_styles.keys())\n",
    "palette = {k: v[0] for k, v in algorithm_styles.items()}\n",
    "\n",
    "def get_algorithm_key(row):\n",
    "    name = row['algo_name']\n",
    "    if name == 'Edlib': return 'edlib'\n",
    "    if name == 'Wfa':\n",
    "        if row.get('job_algo_Wfa_heuristic') != \"None\":\n",
    "            return 'wfa-adaptive'\n",
    "        if row['job_algo_Wfa_memorymodel'] == 'MemoryUltraLow':\n",
    "            return 'biwfa'\n",
    "        else:\n",
    "            return 'wfa'\n",
    "    if name == 'BlockAligner':\n",
    "        return 'blockaligner'\n",
    "    if name == 'AstarPa':\n",
    "        t = row['job_algo_AstarPa_heuristic_type']\n",
    "        r = row['job_algo_AstarPa_heuristic_r']\n",
    "        key = 'astarpa'\n",
    "        if r == 1:\n",
    "            key += '-r1'\n",
    "        if row['job_algo_AstarPa_heuristic_p']:\n",
    "            key += '-preprune'\n",
    "        return key\n",
    "    if name == 'AstarPa2':\n",
    "        key = 'astarpa2'\n",
    "        name = row.job_algo_AstarPa2_name\n",
    "        if name:\n",
    "            return f'{key}-{name}'\n",
    "        if row.job_algo_AstarPa2_front_Bit_sparse:\n",
    "            key += '-sparse'\n",
    "        if row.job_algo_AstarPa2_front_Bit_simd:\n",
    "            key += '-simd'\n",
    "        if row.job_algo_AstarPa2_sparsehcalls:\n",
    "            key += '-h'\n",
    "        return key\n",
    "    return 'unknown'\n",
    "\n",
    "# Returns display name, color, and style for an algorithm\n",
    "def algorithm_display(row, split):\n",
    "    (c, l, n) = algorithm_styles[row['algo_key']]\n",
    "    if 'r' in split:\n",
    "        if row.r:\n",
    "            n += f' (r={row.r})'\n",
    "    return (c, l, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "01a488aa-7a2b-4456-9697-4522919b5368",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_results(path):\n",
    "    # - Read a json file\n",
    "    # - Rename json fields from a_b to a-b\n",
    "    # - Flatten into dataframe\n",
    "    # - Flatten algorithm params into a few fields:\n",
    "    #   - algo_name: the type of algorithm\n",
    "    #   - algo_full: the json-string of algorithm parameters\n",
    "    # - Rename and compute some common columns:\n",
    "    #   - error-rate\n",
    "    #   - length\n",
    "    #   - s_per_pair\n",
    "    #   - p_correct\n",
    "    \n",
    "    json_path = Path(path)\n",
    "    data = json.loads(json_path.read_text())\n",
    "    \n",
    "    # Remove underscores from all keys\n",
    "    def remove_underscores(o):\n",
    "        if isinstance(o, list):\n",
    "            return [remove_underscores(v) for v in o]\n",
    "        if isinstance(o, dict):\n",
    "            return {k.replace('_', ''): remove_underscores(v) for k, v in o.items()}\n",
    "        return o\n",
    "    \n",
    "    data = remove_underscores(data)\n",
    "\n",
    "    # Clean up algo columns\n",
    "    for x in data:\n",
    "        name = list(x['job']['algo'].keys())[0]\n",
    "        obj = x['job']['algo']\n",
    "        obj['name'] = name\n",
    "        x['algo_name'] = name\n",
    "        x['algo_full'] = json.dumps(obj)\n",
    "        #del x['job']['algo']\n",
    "        if 'Ok' in x['output']:\n",
    "            del x['output']['Ok']['costs']\n",
    "\n",
    "    # Flatten the js\n",
    "    df = pd.json_normalize(data, sep='_')\n",
    "    df['algo_key'] = df.apply(get_algorithm_key, axis=1)\n",
    "    df['algo_pretty'] = df['algo_key'].map(lambda key: algorithm_styles[key][2])\n",
    "    \n",
    "    # Convenience renaming\n",
    "    df = df.rename({'job_dataset_Generated_length': 'length',\n",
    "                    'job_dataset_Generated_errorrate': 'errorrate',\n",
    "                    'job_timelimit': 'timelimit',\n",
    "                    'output_Ok_pcorrect': 'pcorrect',\n",
    "                    'output_Ok_measured_runtime': 'runtime',\n",
    "                    'output_Ok_measured_memory': 'memory',\n",
    "                    'stats_divergence_mean': 'divergence',\n",
    "                    'job_algo_AstarPa_diagonaltransition': 'dt',\n",
    "                    'job_algo_AstarPa_heuristic_prune': 'prune',\n",
    "                    'job_algo_AstarPa_heuristic_r': 'r',\n",
    "                    #'job_algo_AstarPa2_heuristic_r': 'r',\n",
    "                   }, axis='columns')\n",
    "    if 'r' not in df.columns:\n",
    "        df['r'] = 1\n",
    "    \n",
    "    # Order rows\n",
    "    df['algo_ord'] = df['algo_key'].map(lambda key: algorithm_order.index(key))\n",
    "    df.sort_values(by='algo_ord', inplace=True, kind = 'stable')\n",
    "    if 'length' in df.columns:\n",
    "        df.sort_values(by='length', inplace=True, kind = 'stable')\n",
    "    if 'errorrate' in df.columns:\n",
    "        df.sort_values(by='errorrate', inplace=True, kind = 'stable')\n",
    "    # Order by dataset\n",
    "    if 'job_dataset_File' in df.columns and df.job_dataset_File.notna().all():\n",
    "        df['dataset'] = df['job_dataset_File'].map(lambda f: Path(f).parent.name)\n",
    "        df['dataset_ord'] = df['dataset'].map(dataset_key)\n",
    "        df.sort_values(by='dataset_ord', inplace=True, kind = 'stable')\n",
    "    \n",
    "    # Computed columns\n",
    "    df['costmodel'] = df.apply(lambda row: (row['job_costs_sub'], row['job_costs_open'], row['job_costs_extend']), axis=1)\n",
    "    df['s_per_pair'] = df['runtime'] / df['stats_seqpairs']\n",
    "    df['timelimit_per_pair'] = df['timelimit'] / df['stats_seqpairs']\n",
    "    if 'length' in df.columns and 'output_Ok_stats_expanded' in df.columns:\n",
    "        df['band'] = df['output_Ok_stats_expanded'] / (df['stats_seqpairs']* df['length'])\n",
    "\n",
    "    def runtime_capped(row):\n",
    "        if not math.isnan(row['runtime']):\n",
    "            return row['runtime']\n",
    "        if row['output_Err'] == 'Timeout':\n",
    "            return row['timelimit']\n",
    "        return row['timelimit']*1.1\n",
    "    df['runtime_capped'] = df.apply(runtime_capped, axis = 1)\n",
    "    df['s_per_pair_capped'] = df['runtime_capped'] / df['stats_seqpairs']\n",
    "    \n",
    "    df['editdistance'] = df['stats_insertions'] + df['stats_deletions'] + df['stats_substitutions']\n",
    "    \n",
    "    # Some specific fixes\n",
    "    df = df.fillna({'r': 0}, downcast='infer')\n",
    "    \n",
    "    # Remove unsupported algos\n",
    "    if 'output_Err' in df.columns:\n",
    "        df = df[df.output_Err != 'Unsupported']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8499c1ef-ee41-40c8-801c-88ab3ab106d0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## The one plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "6bf1c57b-e034-4c70-96ac-c180cacdc153",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot(df,\n",
    "         name='',\n",
    "         file=None,\n",
    "         x='length',\n",
    "         y='s_per_pair',\n",
    "         # Column to use for hue and style.\n",
    "         # Always change both at the same time!\n",
    "         hue='algo_key',\n",
    "         style='r',\n",
    "         # column to use for marker size\n",
    "         size=None,\n",
    "         # Logarithmic axes by default\n",
    "         xlog=True,\n",
    "         xlim=(0, None),\n",
    "         ylog=True,\n",
    "         ylim=None,\n",
    "         # alph\n",
    "         alpha=1.0,\n",
    "         # Use line instead of scatter plot?\n",
    "         connect=False,\n",
    "         # Draw a cone from the given filter and x\n",
    "         cone=None,\n",
    "         cone_x=3*10**4,\n",
    "         fit=False,\n",
    "         line_labels=False,\n",
    "         categorical=False,\n",
    "         ax=None,\n",
    "         width=None,\n",
    "         height=None,\n",
    "         png=False,\n",
    "         mp=None,\n",
    "         minorticks=False,\n",
    "        ):\n",
    "    \n",
    "    if df[y].isna().all():\n",
    "        print(f\"All values of {y} are nan.\")\n",
    "        return\n",
    "    \n",
    "    df = df[df[y].notnull()]\n",
    "    assert not df.empty\n",
    "    \n",
    "    # We group data by this set of keys.\n",
    "    split = [hue, style]\n",
    "    \n",
    "    # Remove 'r' from the split if not both r=1 and r=2 are present,\n",
    "    # to prevent redundant (r=1) in plots.\n",
    "    if 'r' in split and 'r' in df.columns:\n",
    "        if not (1 in df.r.values and 2 in df.r.values):\n",
    "            split.remove('r')\n",
    "    \n",
    "    # Group the data into datapoints per line\n",
    "    groups = df.groupby(split, sort=False)\n",
    "    \n",
    "    # Not sure if needed actually.\n",
    "    sns.reset_defaults()\n",
    "    sns.set_context(None) # 'paper', 'notebook'\n",
    "    \n",
    "    # Set up the figure if not provided.\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "        width = width or 3\n",
    "        height = height or 2\n",
    "        fig.set_size_inches(width, height, forward=True)\n",
    "        hasax = False\n",
    "    else:\n",
    "        hasax = True\n",
    "\n",
    "    \n",
    "    # Set log scales\n",
    "    ax.set(xscale='log' if xlog else 'linear', yscale='log' if ylog else 'linear')\n",
    "    \n",
    "    # limit number of ticks\n",
    "    if ylog:\n",
    "        ax.locator_params(axis='y', numticks=6)\n",
    "        ax.yaxis.set_minor_formatter(plt.NullFormatter())\n",
    "    else:\n",
    "        ax.locator_params(axis='y', nbins=6)\n",
    "\n",
    "    if xlog:\n",
    "        ax.locator_params(axis='x', numticks=6)\n",
    "        ax.xaxis.set_minor_formatter(plt.NullFormatter())\n",
    "    else:\n",
    "        ax.locator_params(axis='x', nbins=5)\n",
    "    \n",
    "    \n",
    "    # PLOTTING\n",
    "    \n",
    "    if not categorical:\n",
    "        # Show a scatterplot of points.\n",
    "        # Each group is plotted separately for more control over its style.\n",
    "        for k, group in groups:\n",
    "            first_row = group.iloc[0]\n",
    "            color, linestyle, grouplabel = algorithm_display(first_row, split)\n",
    "\n",
    "            ax.plot(x,\n",
    "                    y,\n",
    "                    data=group.sort_values(by=x),\n",
    "                    color=color,\n",
    "                    linestyle=linestyle if connect else 'None',\n",
    "                    marker='o',\n",
    "                    alpha=alpha,\n",
    "                    dash_capstyle = 'round',\n",
    "                    label=grouplabel,\n",
    "                    zorder=2,\n",
    "                    markersize=4,\n",
    "                    linewidth=linewidth\n",
    "                   )\n",
    "    if categorical:\n",
    "        # Overlay a boxplot and swarmplot on top of each other\n",
    "        for k, group in groups: \n",
    "            is_exact = group.iloc[0].output_Ok_isexact\n",
    "            marker = 'o' if is_exact else '^'\n",
    "            markersize = 3 if is_exact else 4\n",
    "            sns.swarmplot(data=group,\n",
    "                            x=x,\n",
    "                            y=y,\n",
    "                            hue=hue,\n",
    "                            palette=palette,\n",
    "                            ax=ax,\n",
    "                            size=markersize,\n",
    "                            linewidth=0,\n",
    "                            edgecolor='gray',\n",
    "                            zorder=0.5,\n",
    "                            dodge=False,\n",
    "                            marker=marker,\n",
    "            )\n",
    "        sns.boxplot(data=df,\n",
    "                    x=x,\n",
    "                    y=y,\n",
    "                    ax=ax,\n",
    "                    linewidth=linewidth,\n",
    "                    whis=0,\n",
    "                    showcaps=False,\n",
    "                    showfliers=False,\n",
    "                    boxprops={'facecolor':'None'},\n",
    "                    whiskerprops={'linewidth':0},\n",
    "                    showmeans=True,\n",
    "                    meanprops={\"marker\":\"o\",\n",
    "                               \"markerfacecolor\":\"white\", \n",
    "                               \"markeredgecolor\":\"red\",\n",
    "                               \"markersize\":\"7\"}\n",
    "                    )\n",
    "    \n",
    "    # TEXT\n",
    "    \n",
    "    # Title\n",
    "    if name:\n",
    "        ax.set_title(name, y=1.05)\n",
    "    \n",
    "    # Remove legend\n",
    "    ax.legend().remove()\n",
    "    \n",
    "    # BACKGROUND\n",
    "    ax.set_facecolor(\"#F8F8F8\")\n",
    "    ax.set_axisbelow(True) \n",
    "    ax.grid(False)\n",
    "    if categorical:\n",
    "        ax.tick_params(axis=\"y\", which=\"both\", right=True)\n",
    "        ax.grid(True, axis=\"y\", which=\"major\", color=\"black\", alpha=.5, zorder=0, lw=0.5)\n",
    "        ax.grid(True, axis=\"y\", which=\"minor\", color=\"black\", alpha=.1, zorder=0, lw=0.5)\n",
    "    else:\n",
    "        ax.grid(True, axis=\"y\", which=\"major\", color=\"white\", alpha=1, zorder=0)\n",
    "    \n",
    "    \n",
    "    # AXES\n",
    "    \n",
    "    # Labels\n",
    "    ax.set_xlabel(column_display_name(x))  # weight='bold',\n",
    "    ax.set_ylabel(column_display_name(y), rotation=0, ha=\"left\")\n",
    "    ax.yaxis.set_label_coords(-0.5/width if width else -0.1, 1.00)\n",
    "    \n",
    "    # Limits\n",
    "    x_margin = 1.5\n",
    "    y_margin = 1.5\n",
    "    if xlog:\n",
    "        #xs = df[df[x] > 0][x]\n",
    "        ax.set_xlim(df[x].min() / x_margin, df[x].max() * x_margin)\n",
    "\n",
    "    if ylog:\n",
    "        ax.set_ylim(df[y].min() / y_margin, df[y].max() * y_margin)\n",
    "    \n",
    "    # Start linear scales at 0.\n",
    "    if not xlog and not categorical and x != 'job_costs_open':\n",
    "        ax.set(xlim=xlim)\n",
    "    if not ylog:\n",
    "        ax.set(ylim=(0,None))\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim[0], ylim[1])\n",
    " \n",
    "    \n",
    "    # Show bottom spine, and left spine when xlog=false\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(True)\n",
    "    ax.spines['left'].set_visible(not xlog and not categorical)\n",
    "    \n",
    "    # Format % scales.\n",
    "    if x in ['errorrate', 'divergence']:\n",
    "        ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0, decimals=0))\n",
    "    \n",
    "    # Show major ticks\n",
    "    ax.tick_params(\n",
    "        axis=\"both\",\n",
    "        which=\"major\",\n",
    "        bottom=True,\n",
    "        top=False,\n",
    "        left=True,\n",
    "        right=False,\n",
    "    )\n",
    "    # No minor ticks\n",
    "    ax.tick_params(\n",
    "        axis=\"both\",\n",
    "        which=\"minor\",\n",
    "        bottom=False,\n",
    "        top=False,\n",
    "        left=False,\n",
    "        right=False,\n",
    "        labelbottom=False,  # labels along the bottom edge are off\n",
    "    )\n",
    "    # Do show minor ticks for small log ranges\n",
    "    if ylog and minorticks:\n",
    "         ax.tick_params(axis=\"y\", which=\"minor\", left=True)\n",
    "    \n",
    "    \n",
    "    # CONE\n",
    "    # Fills the region between x**1 and x**2\n",
    "    if cone:\n",
    "        x0 = cone_x\n",
    "        x_max = x_margin * df[x].max()\n",
    "        x_range = (x0, x_max)\n",
    "        \n",
    "        y0 = df[cone(df) & (df[x] == cone_x)][y].max()\n",
    "        y_lin = (y0, y0 * (x_max / x0) ** 1)\n",
    "        y_quad = (y0, y0 * (x_max / x0) ** 2)\n",
    "        ax.fill_between(x_range, y_lin, y_quad, color=\"grey\", alpha=0.15, zorder=0.4)\n",
    "        \n",
    "    # TIME LIMIT\n",
    "    if y=='runtime_capped' or (y=='s_per_pair_capped' and x != 'length'):\n",
    "        timeouts = df[df.runtime.isna()]\n",
    "        if len(timeouts.index) > 0:\n",
    "            # assert len(timeouts.timelimit_per_pair.unique()) == 1, str(timeouts.timelimit_per_pair.unique())\n",
    "\n",
    "            timelimit = timeouts.iloc[0].timelimit_per_pair\n",
    "\n",
    "            # draw a red line at the timelimit.\n",
    "            ax.axhline(y=timelimit, color=\"red\", linestyle=\"-\", alpha=1, linewidth=0.5)\n",
    "\n",
    "            # Modify/add the timelimit ticklabel with TL=\n",
    "            if False:\n",
    "                ylabels = [x for x in ax.get_yticklabels()]\n",
    "                found = False\n",
    "                for i, l in enumerate(ylabels):\n",
    "                    if l.get_position()[1] == timelimit:\n",
    "                        ylabels[i] = \"TL=\" + ylabels[i].get_text()\n",
    "                        found = True\n",
    "                if found:\n",
    "                    ax.set_yticklabels(ylabels)\n",
    "                else:\n",
    "                    yticks = list(ax.get_yticks())\n",
    "                    ylabels = list(ax.get_yticklabels())\n",
    "                    yticks.append(timelimit)\n",
    "                    ylabels.append(\"TLE\")\n",
    "                    ax.set_yticks(yticks)\n",
    "                    try:\n",
    "                        ax.set_yticklabels(ylabels)\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "                    finally:\n",
    "                        pass\n",
    "\n",
    "    # POLY FIT\n",
    "\n",
    "    def angle(slope):\n",
    "        x_min, x_max = ax.get_xlim()\n",
    "        y_min, y_max = ax.get_ylim()\n",
    "        bbox = ax.get_window_extent()\n",
    "        x_sz = bbox.width\n",
    "        y_sz = bbox.height\n",
    "        x_factor = x_sz / (np.log10(x_max) - np.log10(x_min) if xlog else x_max - x_min)\n",
    "        y_factor = y_sz / (np.log10(y_max) - np.log10(y_min) if ylog else y_max - y_min) \n",
    "        slope = slope * y_factor / x_factor\n",
    "        return math.atan(slope)*180/math.pi\n",
    "    \n",
    "    if fit:\n",
    "        assert x=='length' and xlog and ylog, \"Polynomial fits only work in log-log plots with x=length\"\n",
    "        for k, group in groups:\n",
    "            first_row = group.iloc[0]\n",
    "            color, linestyle, grouplabel = algorithm_display(first_row, split)\n",
    "            grouplabel = grouplabel.replace('\\n', ' ')\n",
    "            fit_label = grouplabel\n",
    "            \n",
    "            filtered = group[group.runtime.notnull()]\n",
    "            ps = filtered[[x,y]].dropna()\n",
    "            xmin, xmax = filtered[x].min(), filtered[x].max()\n",
    "            if len(ps) > 1:\n",
    "                fit = np.polyfit(np.log(ps[x]), np.log(ps[y]), 1)\n",
    "                f = lambda x: x**fit[0] * np.exp(fit[1])\n",
    "                # Extra {{ and }} are for the math-mode superscript\n",
    "                fit_label = f\"{grouplabel} $\\sim n^{{{fit[0]:0.2f}}}$\"\n",
    "\n",
    "                ymin, ymax = f(xmin), f(xmax)\n",
    "                # line from xmin to xmax (use plt.axline for infinite line)\n",
    "                ax.plot([xmin, xmax], [ymin, ymax], color=color, linestyle=linestyle, alpha=1, dash_capstyle = 'round', zorder=2, linewidth=linewidth)\n",
    "                #print(f'Exponent for {k}: {fit[0]:0.2f}')\n",
    "\n",
    "            ax.text(\n",
    "                xmax,\n",
    "                min(ymax, ax.get_ylim()[1]),\n",
    "                fit_label,\n",
    "                color=color,\n",
    "                ha=\"right\",\n",
    "                va=\"bottom\",\n",
    "                size=labelsize,\n",
    "                alpha=1,\n",
    "                rotation=angle(fit[0]),\n",
    "                rotation_mode='anchor',\n",
    "            )\n",
    "    if line_labels:\n",
    "        # If no legend and no fits are shown, show manual labels instead\n",
    "        for split_key, group in groups:\n",
    "            first_row = group.iloc[0]\n",
    "            color, linestyle, grouplabel = algorithm_display(first_row, split)\n",
    "\n",
    "            grouplabel = grouplabel.replace('\\n', ' ')\n",
    "\n",
    "            max_idx = group[x].idxmax()\n",
    "            label_x = group[x][max_idx]\n",
    "            label_y = min(group[y][max_idx], ax.get_ylim()[1])\n",
    "            key = split_key[0] if isinstance(split_key, tuple) else split_key\n",
    "            \n",
    "            by_x = group[x].argsort()\n",
    "            last = group.iloc[by_x.iloc[-1]]\n",
    "            before = group.iloc[by_x.iloc[-3]]\n",
    "            slope = (last[y] - before[y])/(last[x] - before[x])\n",
    "            ax.text(\n",
    "                label_x,\n",
    "                label_y,\n",
    "                grouplabel,\n",
    "                color=color,\n",
    "                ha=\"right\",\n",
    "                va=\"bottom\",\n",
    "                size=labelsize,\n",
    "                alpha=1,\n",
    "                rotation=angle(slope),\n",
    "                rotation_mode='anchor',\n",
    "            )\n",
    "\n",
    "    if not hasax:\n",
    "        if file:\n",
    "            plt.savefig(f\"plots/{file}.svg\", dpi=300, bbox_inches='tight')\n",
    "            if png:\n",
    "                plt.savefig(f\"plots/{file}.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "ad51c47a-2e72-4d43-95e8-2ce5fd4a2dda",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Scaling with DIVERGENCE\n",
    "df = read_results(\"results/scaling-e.json\")\n",
    "plot(df, file=f'scaling_e', x='divergence', y='s_per_pair', size=None, xlog=False, ylog=False, connect=True, line_labels=True,\n",
    "     ylim=(0,0.28), width=4.4, height=3)\n",
    "plt.close()\n",
    "plot(df, file=f'scaling_e_zoom', x='divergence', y='s_per_pair', size=None, xlog=False, ylog=False, connect=True, line_labels=True,\n",
    "     ylim=(0,0.079), width=4.4, height=3)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "3ee3ac42-7404-4c23-883b-50fa24473115",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SCALING WITH LENGTH\n",
    "\n",
    "df = read_results(\"results/scaling-n.json\")\n",
    "cone = lambda df: ((df['algo_key'] == 'astarpa-r1') | (df['algo_key'] == 'astarpa'))\n",
    "for e, g in df.groupby('errorrate'):\n",
    "    plot(g, file=f'scaling_n_e{e}', x='length', y='s_per_pair', fit=True, cone=cone, cone_x = 10000, width=4.4, height=3, ylim = (10**-3.9, 10**3.9))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "1f920a96-0536-46d7-9719-838bcd3fca01",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# BOXPLOTS on real data\n",
    "def boxplot(path, w0, row=False, vlines=[], wr=None,wspace=0.15, ylim=None, sharelegend=False, minorticks=False):\n",
    "    df = read_results(f\"results/{path}.json\")\n",
    "    ww=1\n",
    "    datasets = len(df.dataset.unique())\n",
    "    hh = (datasets+ww-1)//ww\n",
    "    if row:\n",
    "        ww,hh=hh,ww\n",
    "    w = ww*w0\n",
    "    h = 3.7 * hh\n",
    "    fig, axs = plt.subplots(hh, ww, figsize=(w, h), gridspec_kw={'width_ratios': wr})\n",
    "    if not isinstance(axs, np.ndarray):\n",
    "        axs = [axs]\n",
    "    if isinstance(axs[0], np.ndarray):\n",
    "        axs = [x for col in zip(*axs) for x in col]\n",
    "    ylim = ylim or [None] * datasets\n",
    "    for (k, g), ax, ylim in zip(df.groupby('dataset',sort=False),axs,ylim):\n",
    "        avg = g.stats_seqpairs.unique().max() > 1\n",
    "        y = 's_per_pair_capped' if avg else 'runtime_capped'\n",
    "        plot(g, x='algo_pretty', y=y,\n",
    "             xlog=False,\n",
    "             ylog=True,\n",
    "             ylim=ylim,\n",
    "             categorical=True,\n",
    "             ax=ax,\n",
    "             width=w,\n",
    "             minorticks=minorticks\n",
    "             )\n",
    "        ax.set_xlabel(dataset_pretty.get(k, k))\n",
    "        if sharelegend:\n",
    "            ax.set(xticklabels=[])\n",
    "    \n",
    "        for x in vlines:\n",
    "            ax.axvline(x=x, color=\"black\", alpha=0.5, linewidth=0.5, zorder=0.1)\n",
    "    \n",
    "    if sharelegend:\n",
    "        keys = g.algo_key.unique()\n",
    "        handles = []\n",
    "        labels = []\n",
    "        for key in keys:\n",
    "            is_exact = g[g.algo_key == key].output_Ok_isexact.unique()[0]\n",
    "            color, style, label = algorithm_styles[key]\n",
    "            marker = 'o' if is_exact else '^'\n",
    "            markersize = 7 if is_exact else 7\n",
    "            labels.append(label.replace('\\n', ' '))\n",
    "            handles.append(mlines.Line2D([], [], color=color, marker=marker, linestyle='None',\n",
    "                                         markersize=markersize))\n",
    "\n",
    "        fig.legend(handles,\n",
    "                   labels,\n",
    "                   loc='lower center',\n",
    "                   ncols=7,\n",
    "                   bbox_to_anchor=[0.5, -0.08],\n",
    "                   markerscale=2.3,\n",
    "                   fontsize=12,\n",
    "                   frameon=False,\n",
    "                   handletextpad=0.1,\n",
    "                   columnspacing=1.5,\n",
    "        )\n",
    "        fig.subplots_adjust(wspace=wspace, hspace=0.4)\n",
    "\n",
    "    plt.savefig(f\"plots/{path}.svg\", bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "776ddfea-00bb-4db8-b752-42621a2effe5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# AVERAGE RUNTIME TABLE\n",
    "import tabulate\n",
    "def table(path):\n",
    "    def key_fn(keys):\n",
    "        return [dataset_key(key)[0] for key in keys]\n",
    "    df = read_results(f\"results/{path}.json\")\n",
    "    df.loc[df.algo_key == 'astarpa-r1', 'algo_key'] = 'astarpa'\n",
    "\n",
    "    table = df.pivot_table(index='algo_key', columns=['dataset'], values='s_per_pair_capped', aggfunc=np.mean, sort=False)\n",
    "    table.sort_index(axis=1, level=0, inplace=True, sort_remaining=False, key=key_fn)\n",
    "\n",
    "    # Best A*PA2 is x faster than best of Edlib/Biwfa.\n",
    "    table.loc['speedup'] =  np.minimum(table.loc['edlib'], table.loc['biwfa'])/np.minimum(table.loc['astarpa2-simple'], table.loc['astarpa2-full']) \n",
    "\n",
    "    table = table.round({'sars-cov-2': 5, 'ont-1k': 6, 'ont-10k': 5, 'ont-50k': 4, 'ont-500k': 2, 'ont-500k-genvar': 2})\n",
    "\n",
    "    table = table.rename(axis=1, level=0, mapper=lambda c: dataset_pretty[c])\n",
    "    table = table.rename(axis=0, mapper=lambda a: algorithm_styles[a][2].replace('\\n', ' '))\n",
    "    # display(table)\n",
    "    print(tabulate.tabulate(table, headers=table.columns, tablefmt='orgtbl'))\n",
    "    #print(table.to_latex())\n",
    "\n",
    "    # TIMEOUTS TABLE\n",
    "    table = df.pivot_table(index='algo_key', columns=['dataset'], values='runtime', aggfunc={'runtime': lambda x: x.isnull().sum()}, sort=False)\n",
    "    table.sort_index(axis=1, level=0, inplace=True, sort_remaining=False, key=key_fn)\n",
    "    table = table.rename(axis=1, level=0, mapper=lambda c: dataset_pretty[c])\n",
    "    table = table.rename(axis=0, mapper=lambda a: algorithm_styles[a][2].replace('\\n', ' '))\n",
    "    print()\n",
    "    print(tabulate.tabulate(table, headers=table.columns, tablefmt='orgtbl'))\n",
    "\n",
    "    # % CORRECT TABLE\n",
    "    df = df[df.output_Ok_isexact == False]\n",
    "    # display(df.algo_name.unique())\n",
    "    # display(df[df.algo_name == 'BlockAligner'].pcorrect)\n",
    "    # df['ncorrect'] = df.pcorrect * df.stats_seqpairs\n",
    "    table = df.pivot_table(index='algo_key', columns=['dataset'], values='pcorrect', aggfunc={'pcorrect': lambda x: x.mean()*100}, sort=False).round(0).astype('int')\n",
    "\n",
    "    table.sort_index(axis=1, level=0, inplace=True, sort_remaining=False, key=key_fn)\n",
    "    table = table.rename(axis=1, level=0, mapper=lambda c: dataset_pretty[c])\n",
    "    table = table.rename(axis=0, mapper=lambda a: algorithm_styles[a][2].replace('\\n', ' '))\n",
    "    print()\n",
    "    print(tabulate.tabulate(table, headers=table.columns, tablefmt='orgtbl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "adc14f98-fd90-47dc-9d7f-d2c9c62ed08a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# INCREMENTAL\n",
    "boxplot('real-incremental', 11, vlines=[1.5, 3.5, 10.5], ylim=[(0.04, 35)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "4fb2af05-a111-433e-a2fb-d869fc9c7cce",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|               |   SARS-CoV-2 pairs |   1kbp ONT reads |   10kbp ONT reads |   >500kbp ONT reads |   >500kbp ONT reads + gen.var. |\n",
      "|---------------+--------------------+------------------+-------------------+---------------------+--------------------------------|\n",
      "| Edlib         |            0.01114 |         0.00011  |            0.008  |                3.74 |                           5.2  |\n",
      "| BiWFA         |            0.00113 |         4.2e-05  |            0.0093 |                4.47 |                           6.96 |\n",
      "| A*PA          |            0.00625 |         0.000514 |            0.1901 |               14.01 |                          12.92 |\n",
      "| WFA Adaptive  |            0.00085 |         3.8e-05  |            0.003  |                1.04 |                           0.81 |\n",
      "| Block Aligner |            0.00235 |         3.8e-05  |            0.0009 |                0.63 |                           0.68 |\n",
      "| A*PA2 simple  |            0.00089 |         5.2e-05  |            0.0014 |                0.58 |                           0.78 |\n",
      "| A*PA2 full    |            0.002   |         8.3e-05  |            0.0017 |                0.2  |                           0.27 |\n",
      "| A*PA2 speedup |            1.2615  |         0.810075 |            5.634  |               18.83 |                          19.01 |\n",
      "\n",
      "|               |   SARS-CoV-2 pairs |   1kbp ONT reads |   10kbp ONT reads |   >500kbp ONT reads |   >500kbp ONT reads + gen.var. |\n",
      "|---------------+--------------------+------------------+-------------------+---------------------+--------------------------------|\n",
      "| Edlib         |                  0 |                0 |                 0 |                   0 |                              0 |\n",
      "| BiWFA         |                  0 |                0 |                 0 |                   0 |                              0 |\n",
      "| A*PA          |                  0 |                0 |                 7 |                   6 |                              3 |\n",
      "| WFA Adaptive  |                  0 |                0 |                 0 |                   0 |                              0 |\n",
      "| Block Aligner |                  0 |                0 |                 0 |                   0 |                              0 |\n",
      "| A*PA2 simple  |                  0 |                0 |                 0 |                   0 |                              0 |\n",
      "| A*PA2 full    |                  0 |                0 |                 0 |                   0 |                              0 |\n",
      "\n",
      "|               |   SARS-CoV-2 pairs |   1kbp ONT reads |   10kbp ONT reads |   >500kbp ONT reads |   >500kbp ONT reads + gen.var. |\n",
      "|---------------+--------------------+------------------+-------------------+---------------------+--------------------------------|\n",
      "| WFA Adaptive  |                 92 |               93 |                49 |                  60 |                              4 |\n",
      "| Block Aligner |                 34 |               85 |                53 |                  96 |                             50 |\n"
     ]
    }
   ],
   "source": [
    "# SUMMARY\n",
    "ymax=[0.1, 0.01, 1, 100, 100]\n",
    "ylim = [(0.00055*x, 0.29*x) for x in ymax]\n",
    "table('real-summary')\n",
    "boxplot('real-summary', 4.0, row=True, wspace=0.22,vlines=[2.5,4.5],ylim=ylim,sharelegend=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "e11bd1c5-1f2b-4e78-a268-33571e9ac798",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# ABLATION\n",
    "boxplot('real-ablation', 6, wr=[7, 7, 11], row=True, vlines=[0.5], wspace=0.11, minorticks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "120fb490-5705-4dc2-901f-d4bfa8040c03",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "boxplot('real-params', 6, wr=[10, 10, 17], row=True, vlines=[0.5], wspace=0.11, minorticks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "124c572f-76d3-4c4c-815b-d958d03ee844",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# SCATTER PLOTS ON REAL DATA\n",
    "# def scatterplot(path, w0, row=False, vlines=[], wr=None,wspace=0.15,ylim=None):\n",
    "#     df = read_results(f\"results/{path}.json\")\n",
    "#     ww=1\n",
    "#     datasets = len(df.dataset.unique())\n",
    "#     hh = (datasets+ww-1)//ww\n",
    "#     if row:\n",
    "#         ww,hh=hh,ww\n",
    "#     w = ww*w0\n",
    "#     h = 3.7 * hh\n",
    "#     fig, axs = plt.subplots(hh, ww, figsize=(w, h), gridspec_kw={'width_ratios': wr})\n",
    "#     if not isinstance(axs, np.ndarray):\n",
    "#         axs = [axs]\n",
    "#     if isinstance(axs[0], np.ndarray):\n",
    "#         axs = [x for col in zip(*axs) for x in col]\n",
    "#     if ylim is None:\n",
    "#         ylim=[None] * datasets\n",
    "#     for (k, g), ax,ylim in zip(df.groupby('dataset',sort=False),axs,ylim):\n",
    "#         avg = g.stats_seqpairs.unique().max() > 1\n",
    "#         plot(g,\n",
    "#              x='divergence',\n",
    "#              y='s_per_pair_capped' if avg else 'runtime_capped',\n",
    "#              hue='algo_key',\n",
    "#              xlog=False,\n",
    "#              ylog=True,\n",
    "#              categorical=False,\n",
    "#              ax=ax,\n",
    "#              width=w,\n",
    "#              xlim=None,\n",
    "#              ylim=ylim\n",
    "#              )\n",
    "#         ax.set_xlabel(dataset_pretty.get(k, k))\n",
    "#         for x in vlines:\n",
    "#             ax.axvline(x=x, color=\"black\", alpha=0.5, linewidth=0.5, zorder=0.1)\n",
    "    \n",
    "#     fig.subplots_adjust(wspace=wspace, hspace=0.4)\n",
    "\n",
    "#     plt.savefig(f\"plots/{path}-scatter.svg\", bbox_inches='tight')\n",
    "#     plt.close()\n",
    "\n",
    "# ymax=[0.1, 0.01, 1, 100, 100]\n",
    "# ylim = [(0.00055*x, 0.29*x) for x in ymax]\n",
    "# scatterplot('real-summary', 4.0, row=True, wspace=0.25, ylim=ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "10b81bd1-5bb7-47fe-8e64-de9cb28bd177",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# TIMING\n",
    "df = read_results(\"results/real-timing.json\")\n",
    "time_labels = {\n",
    "    'precomp': 'Precomputation',\n",
    "    'jrange': 'Computing ranges',\n",
    "    # 'fixedjrange': 'Range to reuse',\n",
    "    'compute': 'Computing blocks',\n",
    "    'pruning': 'Pruning matches',\n",
    "    # 'contoursupdate': 'Contours update',\n",
    "    'tracedt': 'DT trace',\n",
    "    'tracefill': 'Fill trace',\n",
    "    'rest': 'Overhead',\n",
    "}\n",
    "\n",
    "df['output_Ok_stats_tpruning'] += df['output_Ok_stats_tcontoursupdate']\n",
    "df['output_Ok_stats_tjrange'] += df['output_Ok_stats_tfixedjrange']\n",
    "\n",
    "for c in df.columns:\n",
    "    prefix = 'output_Ok_stats_t'\n",
    "    if c.startswith(prefix):\n",
    "        name = c[len(prefix):]\n",
    "        label = time_labels.get(name, name)\n",
    "        df[label] = df[c] / df['stats_seqpairs']\n",
    "\n",
    "def rest(row):\n",
    "    t = row['s_per_pair']\n",
    "    for c in time_labels.values():\n",
    "        if c == 'Overhead': continue\n",
    "        t -= row[c]\n",
    "    return t\n",
    "\n",
    "df['Overhead'] = df.apply(rest, axis=1)\n",
    "\n",
    "datasets = len(df.dataset.unique())\n",
    "fig, axes = plt.subplots(nrows=1, ncols=datasets, figsize=(3.5*datasets, 3.7))\n",
    "fig.subplots_adjust(wspace=0.3)\n",
    "\n",
    "# ymax = [0.0024, 0.00012, 0.00060, 0.0024, 0.24, 0.24]\n",
    "ymax = [0.0024, 0.00012, 0.0024, 0.24, 0.24]\n",
    "\n",
    "for i, ((k, g), ax, ymax) in enumerate(zip(df.groupby('dataset', sort=False), axes, ymax)):\n",
    "    df = g\n",
    "    df.sort_values(by='s_per_pair', inplace=True, kind = 'stable')\n",
    "    df.plot.bar(y = time_labels.values(), stacked=True, width=.9, zorder=2, ax=ax, color = sns.color_palette(), ylim=(0, ymax))\n",
    "    if df.stats_seqpairs.max() > 1:\n",
    "        label = 'Avg. runtime per alignment [s]'\n",
    "    else:\n",
    "        label = 'Runtime per alignment [s]'\n",
    "    ax.set_ylabel(label, rotation=0, ha=\"left\")\n",
    "    ax.set_xlabel(dataset_pretty[k])\n",
    "    if i > 0:\n",
    "        ax.legend().remove()\n",
    "    ax.tick_params(\n",
    "        bottom=False,\n",
    "    )\n",
    "    # ax.ticklabel_format(style='sci', axis='y', scilimits=(0,0),useOffset=False)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.locator_params(axis='y', nbins=2)\n",
    "    # ax.yaxis.set_major_formatter(mtick.LogFormatterSciNotation(labelOnlyBase=False, minor_thresholds=(2,2), linthresh=1))\n",
    "    ax.set_facecolor(\"#F8F8F8\")\n",
    "    ax.grid(False)\n",
    "    ax.grid(True, axis=\"y\", which=\"major\", color=\"w\")\n",
    "    ax.yaxis.set_label_coords(-0.15,1.0)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(True)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    \n",
    "plt.savefig(f\"plots/real-timing.svg\", bbox_inches='tight')    \n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "441e7c83-f0d9-4cc3-bf4a-3dadf867c4db",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|               |   SARS-CoV-2 pairs Median |   SARS-CoV-2 pairs Max |   1kbp ONT reads Median |   1kbp ONT reads Max |   10kbp ONT reads Median |   10kbp ONT reads Max |   >500kbp ONT reads Median |   >500kbp ONT reads Max |   >500kbp ONT reads + gen.var. Median |   >500kbp ONT reads + gen.var. Max |\n",
      "|---------------+---------------------------+------------------------+-------------------------+----------------------+--------------------------+-----------------------+----------------------------+-------------------------+---------------------------------------+------------------------------------|\n",
      "| Edlib         |                         0 |                      0 |                       0 |                    0 |                        0 |                     0 |                          0 |                       0 |                                     0 |                                  0 |\n",
      "| BiWFA         |                         0 |                      0 |                       0 |                    0 |                        0 |                     0 |                          4 |                      11 |                                     0 |                                  2 |\n",
      "| A*PA          |                         0 |                    236 |                       0 |                    0 |                      228 |                   873 |                         84 |                    3453 |                                   158 |                               6868 |\n",
      "| WFA Adaptive  |                         0 |                     11 |                       0 |                    0 |                        0 |                     0 |                          0 |                       0 |                                     0 |                                  0 |\n",
      "| Block Aligner |                         0 |                     16 |                       0 |                    0 |                        0 |                     3 |                        583 |                    1189 |                                   610 |                               2171 |\n",
      "| A*PA2 simple  |                         2 |                      5 |                       0 |                    0 |                        4 |                     6 |                          0 |                      55 |                                     2 |                                164 |\n",
      "| A*PA2 full    |                         0 |                      0 |                       0 |                    0 |                        0 |                     0 |                         30 |                      82 |                                     6 |                                141 |\n"
     ]
    }
   ],
   "source": [
    "# MEMORY USAGE\n",
    "df = read_results(\"results/real-summary.json\")\n",
    "df.loc[df.algo_key == 'astarpa-r1', 'algo_key'] = 'astarpa'\n",
    "df = df[df.memory.notna()]\n",
    "df.memory = df.memory/1000000\n",
    "df['memory2'] = df.memory\n",
    "#df = df[df.algo_key.isin(['edlib', 'biwfa', 'gcsh-dt', 'astarnw', 'astarnw-sparse'])]\n",
    "table = df.pivot_table(index='algo_key', columns=['dataset'], values=['memory2', 'memory'], aggfunc={'memory2': np.median, 'memory': np.max}, sort=False).round(0).astype('int')\n",
    "table =table.rename({'memory2': 'Median', 'memory': 'Max'}, axis='columns')\n",
    "table = table.swaplevel(axis=1)\n",
    "def key_fn(keys):\n",
    "    return [dataset_key(key)[0] for key in keys]\n",
    "table.sort_index(axis=1, level=0, inplace=True, sort_remaining=False, key=key_fn)\n",
    "# Pretty column names\n",
    "table = table.rename(axis=1, level=0, mapper=lambda c: dataset_pretty[c])\n",
    "table = table.rename(axis=0, mapper=lambda a: algorithm_styles[a][2].replace('\\n', ' '))\n",
    "# display(table)\n",
    "import tabulate\n",
    "headers = [' '.join(c) for c in table.columns]\n",
    "print(tabulate.tabulate(table, headers=headers, tablefmt='orgtbl'))\n",
    "#print(table.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d32d39-453d-4acd-8491-a0b2aec276cf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sanity check: CPU frequency\n",
    "# Make sure that the CPU frequency is consistent over all experiments.\n",
    "df = read_results(\"results/real-summary.json\")\n",
    "print(len(df.runtime))\n",
    "print(df.runtime.sum())\n",
    "df = df.rename({'output_Ok_measured_cpufreqstart': 'freqstart','output_Ok_measured_cpufreqend': 'freqend'}, axis='columns')\n",
    "print(df[df.freqstart < 3550][['freqstart','freqend', 'output_Ok_measured_timestart', 'runtime']])\n",
    "print(df[df.freqend < 3550][['freqstart','freqend', 'output_Ok_measured_timestart', 'runtime']])\n",
    "for c in ['freqend', 'freqstart']:\n",
    "    print(c, df[c].min(), df[c].max())\n",
    "    assert df[c].max() < 3650\n",
    "    assert df[c].min() > 3500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa15ae9-1cfd-450c-aa90-ee72a72eac68",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#%history -g -f filename"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (ipykernel)",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "name": "evals.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
