{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ffff657-da07-412e-b61d-5b6adece0db4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# A*PA2 evals\n",
    "\n",
    "This notebook contains the latest evals for A*PA2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c0173d-fe50-4783-a54f-ce498d04328b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='once', category=UserWarning)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b4de93-ed7f-456c-b563-1e3b8f0dc870",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f9c236-f8fa-4c45-b8f9-999fc5d67855",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data reading and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315863b0-e827-4a80-b0fa-1bf6b47915ef",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelsize=10\n",
    "markersize=4\n",
    "linewidth = 0.75\n",
    "\n",
    "def column_display_name(col):\n",
    "    d = {\n",
    "        \"divergence\": \"Divergence\",\n",
    "        \"runtime\": \"Runtime per alignment [s]\",\n",
    "        \"runtime_capped\": \"Runtime per alignment [s]\",\n",
    "        \"s_per_pair\": \"Avg. runtime per alignment [s]\",\n",
    "        \"s_per_pair_capped\": \"Avg. runtime per alignment [s]\",\n",
    "        \"length\": \"Sequence length [bp]\",\n",
    "        \"band\": \"Equivalent band\",\n",
    "        \"algo_key\": \"algorithm\",\n",
    "        \"algo_pretty\": \" \",\n",
    "    }\n",
    "    if col in d:\n",
    "        return d[col]\n",
    "    return col\n",
    "\n",
    "dataset_pretty = {\n",
    "    'ont-ul-500k': 'ONT reads',\n",
    "    'ont-minion-ul-500k': 'ONT reads + genetic variation',\n",
    "    'covid': 'Covid pairs',\n",
    "    'bam2seq_10kto20k': 'BAM 10k',\n",
    "    'overlap_10kto20k': 'overlap 10k',\n",
    "    'bam2seq_100kto200k': 'BAM 100k',\n",
    "    'overlap_100kto200k': 'overlap 100k',\n",
    "    'bam2seq_unrestricted': 'BAM',\n",
    "    'overlap_unrestricted': 'overlap',\n",
    "}\n",
    "dataset_order = list(dataset_pretty.keys())\n",
    "\n",
    "\n",
    "# Line style:\n",
    "# - slow (no pruning): dotted\n",
    "# - normal: solid\n",
    "# - diagonal-transition: dashed\n",
    "# Colours:\n",
    "# edlib/wfa ('extern'): blue/purple\n",
    "# sh/csh/gcsh: orange -> brown -> green gradient\n",
    "# noprune/normal/dt: 60% -> 70% -> 85% saturation\n",
    "colors = {'dijkstra': '#786061', 'sh': \"#e87146\", 'csh': \"#8c662a\", 'gcsh': \"#257d26\"}\n",
    "dashed = (0, (5, 5))\n",
    "dotted = (0, (1, 4))\n",
    "algorithm_styles = {\n",
    "    \"edlib\": (\"#DE4AFF\", dashed, 'Edlib'),\n",
    "    \"biwfa\": (\"#625AFF\", '-', 'BiWFA'),\n",
    "    \"dijkstra\": (colors['dijkstra'], dashed, 'Dijkstra'),\n",
    "    \"sh-noprune\": (colors['sh'], dotted, 'SH (no prune)'),\n",
    "    \"sh\": (colors['sh'], dashed, 'SH'),\n",
    "    \"csh\": (colors['csh'], dashed, 'CSH'),\n",
    "    \"gcsh\": (colors['gcsh'], dashed, 'GCSH'),\n",
    "    \"dijkstra-dt\": (colors['dijkstra'], '-', 'Dijkstra+DT'),\n",
    "    \"sh-dt\": ('#e35522', '-', 'SH+DT'),\n",
    "    \"csh-dt\": ('#875a12', '-', 'CSH+DT'),\n",
    "    \"gcsh-dt\": ('#0f7a10', '-', 'A*PA'),\n",
    "    'gcsh-dt-preprune': ('#0f7a10', '-', 'GCSH+pre\\npruning'),\n",
    "    'astarpa': ('#0f7a10', '-', 'GCSH+DT'),\n",
    "    'astarpa-preprune': ('#0f7a10', '-', 'A*PA++pre\\npruning'),\n",
    "\n",
    "    'astarnw-simple': ('#aacc00', '-', 'A*PA2\\nsimple'),\n",
    "    'astarnw-full': ('#00aaaa', '-', 'A*PA2\\nfull'),\n",
    "\n",
    "    'astarnw': ('#000000', '-', 'A*NW'),\n",
    "    'astarnw-gapgap': ('#bb0000', '-', 'A*NW\\n+gapgap'),\n",
    "    'astarnw-gapdist': ('#ee0000', '-', '\\n\\n+gapdist'),\n",
    "    'astarnw-blocks': ('#ff0000', '-', '\\n\\n\\n+blocks'),\n",
    "    'astarnw-sparse_mem': ('#ff6600', '-', '\\n+sparse mem'),\n",
    "    'astarnw-simd': ('#ffcc00', '-', '\\n\\n+simd'),\n",
    "    'astarnw-ilp': ('#aacc00', '-', '\\nilp'),\n",
    "    'astarnw-new-profile': ('#ffcc00', '-', '\\n\\n+bit-profile'),\n",
    "    'astarnw-sparse_h': ('#ff6600', '-', '\\n+sparse h'),\n",
    "    'astarnw-dt-trace': ('#aacc00', '-', '\\n\\n\\n+DT trace'),\n",
    "    'astarnw-small': ('#aacc00', '-', '\\nsmall'),\n",
    "    'astarnw-incrementaldoubling': ('#ffcc00', '-', '\\n+incremental\\ndoubling'),\n",
    "    'astarnw-SH': ('#77cc00', '-', '+SH'),\n",
    "    'astarnw-SH+prune': ('#77cc00', '-', '\\n+prune'),\n",
    "    'astarnw-pre-pruning': ('#77cc00', '-', '+pre\\npruning'),\n",
    "    'astarnw-prune': ('#00cc77', '-', '\\n\\n+pruning'),\n",
    "    'astarnw-GCSH': ('#00aaaa', '-', '\\n\\n\\n+GCSH'),\n",
    "    \n",
    "    'astarnw-base': ('#00aaaa', '-', 'A*PA2'),\n",
    "    'astarnw-base-r2': ('#0088ff', '-', 'A*PA2 (r=2)'),\n",
    "    'astarnw-GCSH-base': ('#00aaaa', '-', 'GCSH\\nbase'),\n",
    "    'astarnw-nopreprune': ('#00aaaa', '-', '\\n-PP'),\n",
    "    'astarnw-noprune': ('#00aaaa', '-', '\\n\\n-Prune'),\n",
    "    'astarnw-noGCSH': ('#00aaaa', '-', '-GCSH\\n+SH'),\n",
    "    'astarnw-noGCSH-Gap': ('#00aaaa', '-', '-GCSH\\n+gapdist'),\n",
    "    'astarnw-noGCSH-GapGap': ('#00aaaa', '-', '-GCSH\\n+gapgap'),\n",
    "    'astarnw-noid': ('#00aaaa', '-', '\\n\\n-ID'),\n",
    "    'astarnw-nodt': ('#00aaaa', '-', '\\n\\n\\n-DT'),\n",
    "    'astarnw-nosparseh': ('#00aaaa', '-', '-Sparse h'),\n",
    "    'astarnw-noilp': ('#00aaaa', '-', '\\n-ILP'),\n",
    "    'astarnw-nosimd': ('#00aaaa', '-', '\\n\\n-SIMD'),\n",
    "    'astarnw-B512': ('#00aaaa', '-', '\\n\\n\\nB512'),\n",
    "    'astarnw-B128': ('#00aaaa', '-', 'B128'),\n",
    "    'astarnw-B64': ('#00aaaa', '-', '\\nB64'),\n",
    "    'astarnw-f1.5': ('#00aaaa', '-', '\\n\\nf1.5'),\n",
    "    'astarnw-f2.5': ('#00aaaa', '-', '\\n\\n\\nf2.5'),\n",
    "    'astarnw-x5': ('#00aaaa', '-', 'x5'),\n",
    "    'astarnw-x10': ('#00aaaa', '-', 'x10'),\n",
    "    'astarnw-x20': ('#00aaaa', '-', 'x20'),\n",
    "    'astarnw-x2': ('#00aaaa', '-', 'x2'),\n",
    "    'astarnw-k10': ('#00aaaa', '-', 'k10'),\n",
    "    'astarnw-k14': ('#00aaaa', '-', 'k14'),\n",
    "    'astarnw-p7': ('#00aaaa', '-', 'p7'),\n",
    "    'astarnw-p28': ('#00aaaa', '-', 'p28'),\n",
    "    \n",
    "    'astarnw-small-base': ('#aacc00', '-', 'A*PA2-simple'),\n",
    "    'astarnw-small-gapgap': ('#aacc00', '-', 'gapgap'),\n",
    "    'astarnw-small-id': ('#aacc00', '-', '\\n\\n+ID'),\n",
    "    'astarnw-small-nodt': ('#aacc00', '-', '\\n\\n\\n-DT'),\n",
    "    'astarnw-small-nosparseh': ('#aacc00', '-', '-Sparse h'),\n",
    "    'astarnw-small-noilp': ('#aacc00', '-', '\\n-ILP'),\n",
    "    'astarnw-small-nosimd': ('#aacc00', '-', '\\n\\n-SIMD'),\n",
    "    'astarnw-small-B512': ('#aacc00', '-', '\\n\\n\\nB512'),\n",
    "    'astarnw-small-B128': ('#aacc00', '-', 'B128'),\n",
    "    'astarnw-small-B64': ('#aacc00', '-', '\\nB64'),\n",
    "    'astarnw-small-f1.5': ('#aacc00', '-', '\\n\\nf1.5'),\n",
    "    'astarnw-small-f2.5': ('#aacc00', '-', '\\n\\n\\nf2.5'),\n",
    "    'astarnw-small-g40': ('#aacc00', '-', 'g40'),\n",
    "    'astarnw-small-g20': ('#aacc00', '-', 'g20'),\n",
    "    'astarnw-small-g10': ('#aacc00', '-', 'g10'),\n",
    "    'astarnw-small-x5': ('#aacc00', '-', 'x5'),\n",
    "    'astarnw-small-x10': ('#aacc00', '-', 'x10'),\n",
    "    'astarnw-small-x20': ('#aacc00', '-', 'x20'),\n",
    "    'astarnw-small-x2': ('#aacc00', '-', 'x2'),\n",
    "\n",
    "    \"wfa-adaptive\": (\"#625AFF\", '-', 'WFA\\nadaptive'),\n",
    "    'blockaligner': ('#0000ff', '.', 'Block\\nAligner\\n(128,1024)'),\n",
    "}\n",
    "algorithm_order = list(algorithm_styles.keys())\n",
    "palette = {k: v[0] for k, v in algorithm_styles.items()}\n",
    "\n",
    "def get_algorithm_key(row):\n",
    "    name = row['algo_name']\n",
    "    if name == 'Edlib': return 'edlib'\n",
    "    if name == 'Wfa':\n",
    "        if row.get('job_algo_Wfa_heuristic') != \"None\":\n",
    "            return 'wfa-adaptive'\n",
    "        if row['job_algo_Wfa_memorymodel'] == 'MemoryUltraLow':\n",
    "            return 'biwfa'\n",
    "        else:\n",
    "            return 'wfa'\n",
    "    if name == 'BlockAligner':\n",
    "        return 'blockaligner'\n",
    "    if name == 'AstarPa':\n",
    "        t = row['job_algo_AstarPa_heuristic_type']\n",
    "        r = row['job_algo_AstarPa_heuristic_type']\n",
    "        dt = row['job_algo_AstarPa_diagonaltransition']\n",
    "        prune = row['job_algo_AstarPa_heuristic_prune'] if 'job_algo_AstarPa_heuristic_prune' in row else 'Both'\n",
    "        if t == 'None':\n",
    "            key = 'dijkstra'\n",
    "        else:\n",
    "            key = t.lower()\n",
    "        if t != 'None' and prune == 'None':\n",
    "            key += '-noprune'\n",
    "        if dt:\n",
    "            key += '-dt'\n",
    "        if row['job_algo_AstarPa_heuristic_p']:\n",
    "            key += '-preprune'\n",
    "        return key\n",
    "    if name == 'AstarPa2':\n",
    "        key = 'astarnw'\n",
    "        name = row.job_algo_AstarPa2_name\n",
    "        if name:\n",
    "            return f'{key}-{name}'\n",
    "        if row.job_algo_AstarPa2_front_Bit_sparse:\n",
    "            key += '-sparse'\n",
    "        if row.job_algo_AstarPa2_front_Bit_simd:\n",
    "            key += '-simd'\n",
    "        if row.job_algo_AstarPa2_sparsehcalls:\n",
    "            key += '-h'\n",
    "        return key\n",
    "    return 'unknown'\n",
    "\n",
    "# Returns display name, color, and style for an algorithm\n",
    "def algorithm_display(row, split):\n",
    "    (c, l, n) = algorithm_styles[row['algo_key']]\n",
    "    if 'r' in split:\n",
    "        if row.r:\n",
    "            n += f' (r={row.r})'\n",
    "    return (c, l, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e17c2ce-b24b-4a8b-bce4-46f050d1f99b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def read_results(path):\n",
    "    # - Read a json file\n",
    "    # - Rename json fields from a_b to a-b\n",
    "    # - Flatten into dataframe\n",
    "    # - Flatten algorithm params into a few fields:\n",
    "    #   - algo_name: the type of algorithm\n",
    "    #   - algo_full: the json-string of algorithm parameters\n",
    "    # - Rename and compute some common columns:\n",
    "    #   - error-rate\n",
    "    #   - length\n",
    "    #   - s_per_pair\n",
    "    #   - p_correct\n",
    "    \n",
    "    json_path = Path(path)\n",
    "    data = json.loads(json_path.read_text())\n",
    "    \n",
    "    # Remove underscores from all keys\n",
    "    def remove_underscores(o):\n",
    "        if isinstance(o, list):\n",
    "            return [remove_underscores(v) for v in o]\n",
    "        if isinstance(o, dict):\n",
    "            return {k.replace('_', ''): remove_underscores(v) for k, v in o.items()}\n",
    "        return o\n",
    "    \n",
    "    data = remove_underscores(data)\n",
    "\n",
    "    # Clean up algo columns\n",
    "    for x in data:\n",
    "        name = list(x['job']['algo'].keys())[0]\n",
    "        obj = x['job']['algo']\n",
    "        obj['name'] = name\n",
    "        x['algo_name'] = name\n",
    "        x['algo_full'] = json.dumps(obj)\n",
    "        #del x['job']['algo']\n",
    "        if 'Ok' in x['output']:\n",
    "            del x['output']['Ok']['costs']\n",
    "\n",
    "    # Flatten the js\n",
    "    df = pd.json_normalize(data, sep='_')\n",
    "    df['algo_key'] = df.apply(get_algorithm_key, axis=1)\n",
    "    df['algo_pretty'] = df['algo_key'].map(lambda key: algorithm_styles[key][2])\n",
    "    \n",
    "    # Convenience renaming\n",
    "    df = df.rename({'job_dataset_Generated_length': 'length',\n",
    "                    'job_dataset_Generated_errorrate': 'errorrate',\n",
    "                    'job_timelimit': 'timelimit',\n",
    "                    'output_Ok_pcorrect': 'pcorrect',\n",
    "                    'output_Ok_measured_runtime': 'runtime',\n",
    "                    'output_Ok_measured_memory': 'memory',\n",
    "                    'stats_divergence_mean': 'divergence',\n",
    "                    'job_algo_AstarPa_diagonaltransition': 'dt',\n",
    "                    'job_algo_AstarPa_heuristic_prune': 'prune',\n",
    "                    'job_algo_AstarPa_heuristic_r': 'r',\n",
    "                    #'job_algo_AstarPa2_heuristic_r': 'r',\n",
    "                   }, axis='columns')\n",
    "    if 'r' not in df.columns:\n",
    "        df['r'] = 1\n",
    "    \n",
    "    # Order rows\n",
    "    df['algo_ord'] = df['algo_key'].map(lambda key: algorithm_order.index(key))\n",
    "    df.sort_values(by='algo_ord', inplace=True, kind = 'stable')\n",
    "    if 'length' in df.columns:\n",
    "        df.sort_values(by='length', inplace=True, kind = 'stable')\n",
    "    if 'errorrate' in df.columns:\n",
    "        df.sort_values(by='errorrate', inplace=True, kind = 'stable')\n",
    "    # Order by dataset\n",
    "    if 'job_dataset_File' in df.columns and df.job_dataset_File.notna().all():\n",
    "        df['dataset'] = df['job_dataset_File'].map(lambda f: Path(f).parent.name)\n",
    "        df['dataset_ord'] = df['dataset'].map(lambda key: (dataset_order.index(key) if key in dataset_order else 99, key) )\n",
    "        df.sort_values(by='dataset_ord', inplace=True, kind = 'stable')\n",
    "    \n",
    "    # Computed columns\n",
    "    df['costmodel'] = df.apply(lambda row: (row['job_costs_sub'], row['job_costs_open'], row['job_costs_extend']), axis=1)\n",
    "    df['s_per_pair'] = df['runtime'] / df['stats_seqpairs']\n",
    "    df['timelimit_per_pair'] = df['timelimit'] / df['stats_seqpairs']\n",
    "    if 'length' in df.columns and 'output_Ok_stats_expanded' in df.columns:\n",
    "        df['band'] = df['output_Ok_stats_expanded'] / (df['stats_seqpairs']* df['length'])\n",
    "\n",
    "    def runtime_capped(row):\n",
    "        if not math.isnan(row['runtime']):\n",
    "            return row['runtime']\n",
    "        if row['output_Err'] == 'Timeout':\n",
    "            return row['timelimit']\n",
    "        return row['timelimit']*1.1\n",
    "    df['runtime_capped'] = df.apply(runtime_capped, axis = 1)\n",
    "    df['s_per_pair_capped'] = df['runtime_capped'] / df['stats_seqpairs']\n",
    "    \n",
    "    df['editdistance'] = df['stats_insertions'] + df['stats_deletions'] + df['stats_substitutions']\n",
    "    \n",
    "    # Some specific fixes\n",
    "    df = df.fillna({'r': 0}, downcast='infer')\n",
    "    \n",
    "    # Remove unsupported algos\n",
    "    if 'output_Err' in df.columns:\n",
    "        df = df[df.output_Err != 'Unsupported']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acf3277-8017-41a0-a644-17e274eb0c96",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## The one plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd32cae0-663f-47fa-a914-919244118597",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot(df,\n",
    "         name='',\n",
    "         file=None,\n",
    "         x='length',\n",
    "         y='s_per_pair',\n",
    "         # Column to use for hue and style.\n",
    "         # Always change both at the same time!\n",
    "         hue='algo_key',\n",
    "         style='r',\n",
    "         # column to use for marker size\n",
    "         size=None,\n",
    "         # Logarithmic axes by default\n",
    "         xlog=True,\n",
    "         ylog=True,\n",
    "         ylim=None,\n",
    "         # alph\n",
    "         alpha=1.0,\n",
    "         # Use line instead of scatter plot?\n",
    "         connect=False,\n",
    "         # Draw a cone from the given filter and x\n",
    "         cone=None,\n",
    "         cone_x=3*10**4,\n",
    "         fit=False,\n",
    "         line_labels=False,\n",
    "         categorical=False,\n",
    "         ax=None,\n",
    "         width=None,\n",
    "         height=None,\n",
    "         png=False\n",
    "        ):\n",
    "    \n",
    "    if df[y].isna().all():\n",
    "        print(f\"All values of {y} are nan.\")\n",
    "        return\n",
    "    \n",
    "    df = df[df[y].notnull()]\n",
    "    assert not df.empty\n",
    "    \n",
    "    # We group data by this set of keys.\n",
    "    split = [hue, style]\n",
    "    \n",
    "    # Remove 'r' from the split if not both r=1 and r=2 are present,\n",
    "    # to prevent redundant (r=1) in plots.\n",
    "    if 'r' in split and 'r' in df.columns:\n",
    "        if not (1 in df.r.values and 2 in df.r.values):\n",
    "            split.remove('r')\n",
    "    \n",
    "    # Group the data into datapoints per line\n",
    "    groups = df.groupby(split, sort=False)\n",
    "    \n",
    "    # Not sure if needed actually.\n",
    "    sns.reset_defaults()\n",
    "    sns.set_context(None) # 'paper', 'notebook'\n",
    "    \n",
    "    # Set up the figure if not provided.\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(width if width else 3, height if height else 2, forward=True)\n",
    "        hasax = False\n",
    "    else:\n",
    "        hasax = True\n",
    "\n",
    "    \n",
    "    # Set log scales\n",
    "    ax.set(xscale='log' if xlog else 'linear', yscale='log' if ylog else 'linear')\n",
    "    \n",
    "    # limit number of ticks\n",
    "    if ylog:\n",
    "        ax.locator_params(axis='y', numticks=6)\n",
    "    else:\n",
    "        ax.locator_params(axis='y', nbins=6)\n",
    "    \n",
    "    \n",
    "    # PLOTTING\n",
    "    \n",
    "    if not categorical:\n",
    "        # Show a scatterplot of points.\n",
    "        # Each group is plotted separately for more control over its style.\n",
    "        for k, group in groups:\n",
    "            first_row = group.iloc[0]\n",
    "            color, linestyle, grouplabel = algorithm_display(first_row, split)\n",
    "\n",
    "            ax.plot(x,\n",
    "                    y,\n",
    "                    data=group.sort_values(by=x),\n",
    "                    color=color,\n",
    "                    linestyle=linestyle if connect else 'None',\n",
    "                    marker='o',\n",
    "                    alpha=alpha,\n",
    "                    dash_capstyle = 'round',\n",
    "                    label=grouplabel,\n",
    "                    zorder=2,\n",
    "                    markersize=markersize,\n",
    "                    linewidth=linewidth\n",
    "                   )\n",
    "    if categorical:\n",
    "        # Overlay a boxplot and swarmplot on top of each other\n",
    "        sns.swarmplot(data=df,\n",
    "                        x=x,\n",
    "                        y=y,\n",
    "                        hue=hue,\n",
    "                        palette=palette,\n",
    "                        ax=ax,\n",
    "                        size=3,\n",
    "                        linewidth=0,\n",
    "                        edgecolor='gray',\n",
    "                        zorder=0.5,\n",
    "                        dodge=False,\n",
    "        )\n",
    "        sns.boxplot(data=df,\n",
    "                    x=x,\n",
    "                    y=y,\n",
    "                    ax=ax,\n",
    "                    linewidth=linewidth,\n",
    "                    whis=0,\n",
    "                    showcaps=False,\n",
    "                    showfliers=False,\n",
    "                    boxprops={'facecolor':'None'},\n",
    "                    whiskerprops={'linewidth':0},\n",
    "                   )\n",
    "    \n",
    "    # TEXT\n",
    "    \n",
    "    # Title\n",
    "    if name:\n",
    "        ax.set_title(name, y=1.05)\n",
    "    \n",
    "    # Remove legend\n",
    "    ax.legend().remove()\n",
    "    \n",
    "    # BACKGROUND\n",
    "    ax.set_facecolor(\"#F8F8F8\")\n",
    "    ax.set_axisbelow(True) \n",
    "    ax.grid(False)\n",
    "    if categorical:\n",
    "        ax.tick_params(axis=\"y\", which=\"both\", right=True)\n",
    "        ax.grid(True, axis=\"y\", which=\"major\", color=\"black\", alpha=.5, zorder=0, lw=0.5)\n",
    "        ax.grid(True, axis=\"y\", which=\"minor\", color=\"black\", alpha=.1, zorder=0, lw=0.5)\n",
    "    else:\n",
    "        ax.grid(True, axis=\"y\", which=\"major\", color=\"white\", alpha=1, zorder=0)\n",
    "    \n",
    "    \n",
    "    # AXES\n",
    "    \n",
    "    # Labels\n",
    "    ax.set_xlabel(column_display_name(x))  # weight='bold',\n",
    "    ax.set_ylabel(column_display_name(y), rotation=0, ha=\"left\")\n",
    "    ax.yaxis.set_label_coords(-0.10, 1.00)\n",
    "    \n",
    "    # Limits\n",
    "    x_margin = 1.5\n",
    "    y_margin = 1.5\n",
    "    if xlog:\n",
    "        #xs = df[df[x] > 0][x]\n",
    "        ax.set_xlim(df[x].min() / x_margin, df[x].max() * x_margin)\n",
    "\n",
    "    if ylog:\n",
    "        ax.set_ylim(df[y].min() / y_margin, df[y].max() * y_margin)\n",
    "    \n",
    "    # Start linear scales at 0.\n",
    "    if not xlog and not categorical and x != 'job_costs_open':\n",
    "        ax.set(xlim=(0,None))\n",
    "    if not ylog:\n",
    "        ax.set(ylim=(0,None))\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim[0], ylim[1])\n",
    " \n",
    "    \n",
    "    # Show bottom spine, and left spine when xlog=false\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(True)\n",
    "    ax.spines['left'].set_visible(not xlog and not categorical)\n",
    "    \n",
    "    # Format % scales.\n",
    "    if x in ['errorrate', 'divergence']:\n",
    "        ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0, decimals=0))\n",
    "    \n",
    "    # Show major ticks\n",
    "    ax.tick_params(\n",
    "        axis=\"both\",\n",
    "        which=\"major\",\n",
    "        bottom=True,\n",
    "        top=False,\n",
    "        left=True,\n",
    "        right=False,\n",
    "    )\n",
    "    # No minor ticks\n",
    "    ax.tick_params(\n",
    "        axis=\"both\",\n",
    "        which=\"minor\",\n",
    "        bottom=False,\n",
    "        top=False,\n",
    "        left=False,\n",
    "        right=False,\n",
    "        labelbottom=False,  # labels along the bottom edge are off\n",
    "    )\n",
    "    # Do show minor ticks for small log ranges\n",
    "    if ylog:\n",
    "         ax.tick_params(axis=\"y\", which=\"minor\", left=True)\n",
    "    \n",
    "    \n",
    "    # CONE\n",
    "    # Fills the region between x**1 and x**2\n",
    "    if cone:\n",
    "        x0 = cone_x\n",
    "        x_max = x_margin * df[x].max()\n",
    "        x_range = (x0, x_max)\n",
    "        \n",
    "        y0 = df[cone(df) & (df[x] == cone_x)][y].max()\n",
    "        y_lin = (y0, y0 * (x_max / x0) ** 1)\n",
    "        y_quad = (y0, y0 * (x_max / x0) ** 2)\n",
    "        ax.fill_between(x_range, y_lin, y_quad, color=\"grey\", alpha=0.15, zorder=0.4)\n",
    "        \n",
    "    # TIME LIMIT\n",
    "    if y=='runtime_capped' or (y=='s_per_pair_capped' and x != 'length'):\n",
    "        timelimit = df.timelimit_per_pair.iloc[0]\n",
    "        assert df[df.runtime.isna()].timelimit_per_pair.eq(timelimit).all()\n",
    "        \n",
    "        # Draw a red line at the timelimit.\n",
    "        ax.axhline(y=timelimit, color=\"red\", linestyle=\"-\", alpha=1, linewidth=0.5)\n",
    "        \n",
    "        # Modify/add the timelimit ticklabel with TL=\n",
    "        if False:\n",
    "            ylabels = [x for x in ax.get_yticklabels()]\n",
    "            found = False\n",
    "            for i, l in enumerate(ylabels):\n",
    "                if l.get_position()[1] == timelimit:\n",
    "                    ylabels[i] = \"TL=\" + ylabels[i].get_text()\n",
    "                    found = True\n",
    "            if found:\n",
    "                ax.set_yticklabels(ylabels)\n",
    "            else:\n",
    "                yticks = list(ax.get_yticks())\n",
    "                ylabels = list(ax.get_yticklabels())\n",
    "                yticks.append(timelimit)\n",
    "                ylabels.append(\"TLE\")\n",
    "                ax.set_yticks(yticks)\n",
    "                try:\n",
    "                    ax.set_yticklabels(ylabels)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                finally:\n",
    "                    pass\n",
    "            \n",
    "    # POLY FIT\n",
    "\n",
    "    def angle(slope):\n",
    "        x_min, x_max = ax.get_xlim()\n",
    "        y_min, y_max = ax.get_ylim()\n",
    "        bbox = ax.get_window_extent()\n",
    "        x_sz = bbox.width\n",
    "        y_sz = bbox.height\n",
    "        x_factor = x_sz / (np.log10(x_max) - np.log10(x_min) if xlog else x_max - x_min)\n",
    "        y_factor = y_sz / (np.log10(y_max) - np.log10(y_min) if ylog else y_max - y_min) \n",
    "        slope = slope * y_factor / x_factor\n",
    "        return math.atan(slope)*180/math.pi\n",
    "    \n",
    "    if fit:\n",
    "        assert x=='length' and xlog and ylog, \"Polynomial fits only work in log-log plots with x=length\"\n",
    "        for k, group in groups:\n",
    "            first_row = group.iloc[0]\n",
    "            color, linestyle, grouplabel = algorithm_display(first_row, split)\n",
    "            fit_label = grouplabel\n",
    "            \n",
    "            filtered = group[group.runtime.notnull()]\n",
    "            ps = filtered[[x,y]].dropna()\n",
    "            xmin, xmax = filtered[x].min(), filtered[x].max()\n",
    "            if len(ps) > 1:\n",
    "                fit = np.polyfit(np.log(ps[x]), np.log(ps[y]), 1)\n",
    "                f = lambda x: x**fit[0] * np.exp(fit[1])\n",
    "                # Extra {{ and }} are for the math-mode superscript\n",
    "                fit_label = f\"{grouplabel} $\\sim n^{{{fit[0]:0.2f}}}$\"\n",
    "\n",
    "                ymin, ymax = f(xmin), f(xmax)\n",
    "                # line from xmin to xmax (use plt.axline for infinite line)\n",
    "                ax.plot([xmin, xmax], [ymin, ymax], color=color, linestyle=linestyle, alpha=1, dash_capstyle = 'round', label=grouplabel, zorder=2, linewidth=linewidth)\n",
    "                #print(f'Exponent for {k}: {fit[0]:0.2f}')\n",
    "\n",
    "            ax.text(\n",
    "                xmax,\n",
    "                min(ymax, ax.get_ylim()[1]),\n",
    "                fit_label,\n",
    "                color=color,\n",
    "                ha=\"right\",\n",
    "                va=\"bottom\",\n",
    "                size=labelsize,\n",
    "                alpha=1,\n",
    "                rotation=angle(fit[0]),\n",
    "                rotation_mode='anchor',\n",
    "            )\n",
    "    if line_labels:\n",
    "        # If no legend and no fits are shown, show manual labels instead\n",
    "        for split_key, group in groups:\n",
    "            first_row = group.iloc[0]\n",
    "            color, linestyle, grouplabel = algorithm_display(first_row, split)\n",
    "            max_idx = group[x].idxmax()\n",
    "            label_x = group[x][max_idx]\n",
    "            label_y = min(group[y][max_idx], ax.get_ylim()[1])\n",
    "            key = split_key[0] if isinstance(split_key, tuple) else split_key\n",
    "            \n",
    "            by_x = group[x].argsort()\n",
    "            last = group.iloc[by_x.iloc[-1]]\n",
    "            before = group.iloc[by_x.iloc[-3]]\n",
    "            slope = (last[y] - before[y])/(last[x] - before[x])\n",
    "            ax.text(\n",
    "                label_x,\n",
    "                label_y,\n",
    "                grouplabel,\n",
    "                color=color,\n",
    "                ha=\"right\",\n",
    "                va=\"bottom\",\n",
    "                size=labelsize,\n",
    "                alpha=1,\n",
    "                rotation=angle(slope),\n",
    "                rotation_mode='anchor',\n",
    "            )\n",
    "\n",
    "    if not hasax:\n",
    "        if file:\n",
    "            plt.savefig(f\"plots/{file}.pdf\", dpi=300, bbox_inches='tight')\n",
    "            if png:\n",
    "                plt.savefig(f\"plots/{file}.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508cf978-5902-4a69-8bb9-a728e3a06a74",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scaling with length\n",
    "\n",
    "df = read_results('results/scaling-n.json')\n",
    "    \n",
    "df.loc[df['algo_key'] == 'edlib', 'dt'] = False\n",
    "df.loc[df['algo_key'] == 'biwfa', 'dt'] = True\n",
    "\n",
    "cone = lambda df: (df['algo_key'] == 'gcsh-dt') & (df['r'] == (1 if e <= 0.05 else 2))\n",
    "for e, g in df.groupby('errorrate'):\n",
    "    plot(g, file=f'scaling_n_e{e}', x='length', y='s_per_pair', fit=True, cone=cone, cone_x = 10**4, width=4.4, height=3)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbcbbdd-50f0-449d-9306-52d390b5c427",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scaling with divergence\n",
    "df = read_results(\"results/scaling-e.json\")\n",
    "plot(df, file=f'scaling_e', x='divergence', y='s_per_pair', size=None, xlog=False, ylog=False, connect=True, line_labels=True,\n",
    "     ylim=(0,0.69), width=4.4, height=3)\n",
    "plot(df, file=f'scaling_e_zoom', x='divergence', y='s_per_pair', size=None, xlog=False, ylog=False, connect=True, line_labels=True,\n",
    "     ylim=(0,0.29), width=4.4, height=3)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67455ed7-cbf1-4615-8590-40465e3110a1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Boxplots on real data\n",
    "from pathlib import Path\n",
    "warnings.simplefilter('ignore', category=UserWarning)\n",
    "def boxplot(path, w, row=False, vlines=[]):\n",
    "    df = read_results(f\"results/{path}.json\")\n",
    "    ww=1\n",
    "    datasets = len(df.dataset.unique())\n",
    "    hh = (datasets+ww-1)//ww\n",
    "    if row:\n",
    "        ww,hh=hh,ww\n",
    "    w *= ww\n",
    "    h = 3.7 * hh\n",
    "    fig, axs = plt.subplots(hh, ww, figsize=(w, h))\n",
    "    if not isinstance(axs, np.ndarray):\n",
    "        axs = [axs]\n",
    "    if isinstance(axs[0], np.ndarray):\n",
    "        axs = [x for col in zip(*axs) for x in col]\n",
    "    for (k, g), ax in zip(df.groupby('dataset',sort=False),axs):\n",
    "        plot(g, x='algo_pretty', y='s_per_pair_capped', xlog=False, ylog=True, ylim=None, categorical=True, ax=ax)\n",
    "        ax.set_xlabel(dataset_pretty.get(k, k))\n",
    "        for x in vlines:\n",
    "            ax.axvline(x=x, color=\"black\", alpha=0.5, linewidth=0.5, zorder=0.1)\n",
    "    \n",
    "    fig.subplots_adjust(wspace=0.15 if row else .05, hspace=0.3)\n",
    "\n",
    "    plt.savefig(f\"plots/{path}.pdf\", bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3f4b9d-5ab6-49b0-af48-f15d6bddbd28",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boxplot('real', 11, vlines=[1.5, 3.5, 11.5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346bf045-f5d6-4fea-9076-f66fc9d23f19",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# todo: timelimit 100s\n",
    "boxplot('real-summary', 4.5, row=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2643948-eb64-4c0a-a1d9-98f859f81178",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boxplot('real-ablation', 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abb1e56-640d-46c5-aaf4-76cf757c8402",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7577594f-1994-4697-8bf8-50bc3354cfa9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = read_results(\"results/real.json\")\n",
    "df.memory = (df.memory/1000000)\n",
    "df['capped_memory'] = df.memory.fillna(1000000)\n",
    "#df = df[df.algo_key.isin(['edlib', 'biwfa', 'gcsh-dt', 'astarnw', 'astarnw-sparse'])]\n",
    "table = df.pivot_table(index='algo_pretty', columns=['dataset'], values=['capped_memory', 'memory'], aggfunc={'capped_memory': np.median, 'memory': np.max}, sort=False).round(0).astype('int')\n",
    "table =table.rename({'capped_memory': 'Median', 'memory': 'Max'}, axis='columns')\n",
    "table = table.swaplevel(axis=1)\n",
    "table.sort_index(axis=1, level=0, inplace=True, kind='stable', ascending=False)\n",
    "display(table)\n",
    "#print(table.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e295e822-f319-41fe-b21b-1a87c794c43e",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Sanity check: CPU frequency\n",
    "Make sure that the CPU frequency is consistent over all experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67938fe-6d27-4945-b503-07924df89577",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = read_results(\"results/real.json\")\n",
    "df = df.rename({'output_Ok_measured_cpufreqstart': 'freqstart','output_Ok_measured_cpufreqend': 'freqend'}, axis='columns')\n",
    "for c in ['freqstart', 'freqend']:\n",
    "    print(df[c].min(), df[c].max())\n",
    "    assert df[c].min() > 3250\n",
    "    assert df[c].max() < 3350"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (ipykernel)",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "name": "evals.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
