{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ffff657-da07-412e-b61d-5b6adece0db4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# A*PA2 evals\n",
    "\n",
    "This notebook contains the latest evals for A*PA2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c0173d-fe50-4783-a54f-ce498d04328b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='once', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b4de93-ed7f-456c-b563-1e3b8f0dc870",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f9c236-f8fa-4c45-b8f9-999fc5d67855",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data reading and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315863b0-e827-4a80-b0fa-1bf6b47915ef",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelsize=10\n",
    "markersize=4\n",
    "linewidth = 0.75\n",
    "\n",
    "def column_display_name(col):\n",
    "    d = {\n",
    "        \"divergence\": \"Divergence\",\n",
    "        \"runtime\": \"Runtime per alignment [s]\",\n",
    "        \"runtime_capped\": \"Runtime per alignment [s]\",\n",
    "        \"s_per_pair\": \"Avg. runtime per alignment [s]\",\n",
    "        \"s_per_pair_capped\": \"Avg. runtime per alignment [s]\",\n",
    "        \"length\": \"Sequence length [bp]\",\n",
    "        \"band\": \"Equivalent band\",\n",
    "        \"algo_key\": \"algorithm\",\n",
    "        \"algo_pretty\": \" \",\n",
    "    }\n",
    "    if col in d:\n",
    "        return d[col]\n",
    "    return col\n",
    "\n",
    "dataset_pretty = {\n",
    "    'ont-ul-500k': '>500kbp ONT reads',\n",
    "    'ont-minion-ul-500k': '>500kbp ONT reads + genetic variation',\n",
    "    'sars-cov-2': 'SARS-CoV-2 pairs',\n",
    "    'ont-minion-ul-1k-split': '<1kbp ONT reads',\n",
    "    'ont-minion-ul-10k-split': '<10kbp ONT reads',\n",
    "    'ont-minion-ul-50k-split': '<50kbp ONT reads',\n",
    "    'bam2seq_10kto20k': 'BAM 10k',\n",
    "    'overlap_10kto20k': 'overlap 10k',\n",
    "    'bam2seq_100kto200k': 'BAM 100k',\n",
    "    'overlap_100kto200k': 'overlap 100k',\n",
    "    'bam2seq_unrestricted': 'BAM',\n",
    "    'overlap_unrestricted': 'overlap',\n",
    "}\n",
    "dataset_order = list(dataset_pretty.keys())\n",
    "def dataset_key(key):\n",
    "    return (dataset_order.index(key) if key in dataset_order else 99, key) \n",
    "\n",
    "\n",
    "# Line style:\n",
    "# - slow (no pruning): dotted\n",
    "# - normal: solid\n",
    "# - diagonal-transition: dashed\n",
    "# Colours:\n",
    "# edlib/wfa ('extern'): blue/purple\n",
    "# sh/csh/gcsh: orange -> brown -> green gradient\n",
    "# noprune/normal/dt: 60% -> 70% -> 85% saturation\n",
    "colors = {'dijkstra': '#786061', 'sh': \"#e87146\", 'csh': \"#8c662a\", 'gcsh': \"#257d26\"}\n",
    "dashed = (0, (5, 5))\n",
    "dotted = (0, (1, 4))\n",
    "algorithm_styles = {\n",
    "    \"edlib\": (\"#DE4AFF\", '-', 'Edlib'),\n",
    "    \"biwfa\": (\"#625AFF\", '-', 'BiWFA'),\n",
    "    'astarpa': ('#0f7a10', '-', 'A*PA'),\n",
    "    'astarpa-r1': ('#0f7a10', '-', 'A*PA\\n(r=1)'),\n",
    "    'astarpa-preprune': ('#0f7a10', '-', '+PP'),\n",
    "\n",
    "    # Summary\n",
    "    'astarpa2-simple': ('#aa0000', '-', 'A*PA2\\nsimple'),\n",
    "    'astarpa2-full': ('#00aaaa', '-', 'A*PA2\\nfull'),\n",
    "\n",
    "    # Timing\n",
    "    'astarpa2-t_simple': ('#aa0000', '-', 'A*PA2\\nsimple'),\n",
    "    'astarpa2-t_full': ('#00aaaa', '-', 'A*PA2\\nfull'),\n",
    "\n",
    "    # Incremental\n",
    "    'astarpa2-gapgap': ('#aa0000', '-', 'A*PA2\\nBand\\nDoubling'),\n",
    "    'astarpa2-gapdist': ('#aa0000', '-', '\\n+A*'),\n",
    "    'astarpa2-blocks': ('#aa0000', '-', '+Blocks'),\n",
    "    'astarpa2-sparse_mem': ('#aa0000', '-', '\\n+Sparse\\nmemory'),\n",
    "    'astarpa2-simd': ('#aa0000', '-', '+SIMD'),\n",
    "    'astarpa2-ilp': ('#aa0000', '-', '\\n+ILP'),\n",
    "    'astarpa2-new-profile': ('#aa0000', '-', '\\n+bit-profile'),\n",
    "    'astarpa2-dt-trace': ('#aa0000', '-', '\\n+DT\\ntrace'),\n",
    "    'astarpa2-sparse_h': ('#aa0000', '-', '+Sparse h'),\n",
    "    'astarpa2-incrementaldoubling': ('#00aaaa', '-', '+ID'),\n",
    "    'astarpa2-SH': ('#00aaaa', '-', '+SH'),\n",
    "    'astarpa2-prune': ('#00aaaa', '-', '+Pruning'),\n",
    "    'astarpa2-pre-pruning': ('#00aaaa', '-', '\\n+PP'),\n",
    "    'astarpa2-GCSH': ('#00aaaa', '-', '\\n+GCSH'),\n",
    "    \n",
    "    # Ablation full\n",
    "    'astarpa2-GCSH-base': ('#00aaaa', '-', 'GCSH\\nbase'),\n",
    "    'astarpa2-noGCSH-GapGap': ('#00aaaa', '-', '-A*'),\n",
    "    'astarpa2-noGCSH-Gap': ('#00aaaa', '-', '-GCSH\\n+Gap-h'),\n",
    "    'astarpa2-nosimd': ('#00aaaa', '-', '-SIMD'),\n",
    "    'astarpa2-noilp': ('#00aaaa', '-', '-ILP'),\n",
    "    'astarpa2-nodt': ('#00aaaa', '-', '-DT'),\n",
    "    'astarpa2-nosparseh': ('#00aaaa', '-', '-Sparse h'),\n",
    "    'astarpa2-noid': ('#00aaaa', '-', '-ID'),\n",
    "    'astarpa2-noGCSH': ('#00aaaa', '-', '-GCSH\\n+SH'),\n",
    "    'astarpa2-noprune': ('#00aaaa', '-', '-Prune'),\n",
    "    'astarpa2-nopreprune': ('#00aaaa', '-', '-PP'),\n",
    "    'astarpa2-r2': ('#00aaaa', '-', 'r2'),\n",
    "\n",
    "    # Ablation simple\n",
    "    'astarpa2-simple-base': ('#cc0000', '-', 'A*PA2-simple'),\n",
    "    'astarpa2-simple-gapgap': ('#cc0000', '-', '-A*'),\n",
    "    'astarpa2-simple-nosimd': ('#cc0000', '-', '-SIMD'),\n",
    "    'astarpa2-simple-noilp': ('#cc0000', '-', '-ILP'),\n",
    "    'astarpa2-simple-id': ('#cc0000', '-', '+ID'),\n",
    "    'astarpa2-simple-nosparseh': ('#cc0000', '-', '-Sparse h'),\n",
    "    'astarpa2-simple-nodt': ('#cc0000', '-', '-DT'),\n",
    "\n",
    "    # Parameters\n",
    "    # heuristic related\n",
    "    'astarpa2-k10': ('#00aaaa', '-', 'k10'),\n",
    "    'astarpa2-k14': ('#00aaaa', '-', 'k14'),\n",
    "    'astarpa2-p7': ('#00aaaa', '-', 'p7'),\n",
    "    'astarpa2-p28': ('#00aaaa', '-', 'p28'),\n",
    "    # engineering related\n",
    "    'astarpa2-f1.5': ('#00aaaa', '-', 'f1.5'),\n",
    "    'astarpa2-f2.5': ('#00aaaa', '-', 'f2.5'),\n",
    "    'astarpa2-B512': ('#00aaaa', '-', 'B512'),\n",
    "    'astarpa2-B128': ('#00aaaa', '-', 'B128'),\n",
    "    'astarpa2-B64': ('#00aaaa', '-', 'B64'),\n",
    "    'astarpa2-g80': ('#00aaaa', '-', 'g80'),\n",
    "    'astarpa2-g40': ('#00aaaa', '-', 'g40'),\n",
    "    'astarpa2-g20': ('#00aaaa', '-', 'g20'),\n",
    "    'astarpa2-g10': ('#00aaaa', '-', 'g10'),\n",
    "    'astarpa2-x5': ('#00aaaa', '-', 'x5'),\n",
    "    'astarpa2-x10': ('#00aaaa', '-', 'x10'),\n",
    "    'astarpa2-x20': ('#00aaaa', '-', 'x20'),\n",
    "    'astarpa2-x2': ('#00aaaa', '-', 'x2'),\n",
    "    \n",
    "\n",
    "    # Simple parameters\n",
    "    # only engineering related\n",
    "    'astarpa2-simple-f1.5': ('#cc0000', '-', 'f1.5'),\n",
    "    'astarpa2-simple-f2.5': ('#cc0000', '-', 'f2.5'),\n",
    "    'astarpa2-simple-B512': ('#cc0000', '-', 'B512'),\n",
    "    'astarpa2-simple-B128': ('#cc0000', '-', 'B128'),\n",
    "    'astarpa2-simple-B64': ('#cc0000', '-', 'B64'),\n",
    "    'astarpa2-simple-g80': ('#cc0000', '-', 'g80'),\n",
    "    'astarpa2-simple-g40': ('#cc0000', '-', 'g40'),\n",
    "    'astarpa2-simple-g20': ('#cc0000', '-', 'g20'),\n",
    "    'astarpa2-simple-g10': ('#cc0000', '-', 'g10'),\n",
    "    'astarpa2-simple-x5': ('#cc0000', '-', 'x5'),\n",
    "    'astarpa2-simple-x10': ('#cc0000', '-', 'x10'),\n",
    "    'astarpa2-simple-x20': ('#cc0000', '-', 'x20'),\n",
    "    'astarpa2-simple-x2': ('#cc0000', '-', 'x2'),\n",
    "}\n",
    "algorithm_order = list(algorithm_styles.keys())\n",
    "palette = {k: v[0] for k, v in algorithm_styles.items()}\n",
    "\n",
    "def get_algorithm_key(row):\n",
    "    name = row['algo_name']\n",
    "    if name == 'Edlib': return 'edlib'\n",
    "    if name == 'Wfa':\n",
    "        if row.get('job_algo_Wfa_heuristic') != \"None\":\n",
    "            return 'wfa-adaptive'\n",
    "        if row['job_algo_Wfa_memorymodel'] == 'MemoryUltraLow':\n",
    "            return 'biwfa'\n",
    "        else:\n",
    "            return 'wfa'\n",
    "    if name == 'BlockAligner':\n",
    "        return 'blockaligner'\n",
    "    if name == 'AstarPa':\n",
    "        t = row['job_algo_AstarPa_heuristic_type']\n",
    "        r = row['job_algo_AstarPa_heuristic_r']\n",
    "        key = 'astarpa'\n",
    "        if r == 1:\n",
    "            key += '-r1'\n",
    "        if row['job_algo_AstarPa_heuristic_p']:\n",
    "            key += '-preprune'\n",
    "        return key\n",
    "    if name == 'AstarPa2':\n",
    "        key = 'astarpa2'\n",
    "        name = row.job_algo_AstarPa2_name\n",
    "        if name:\n",
    "            return f'{key}-{name}'\n",
    "        if row.job_algo_AstarPa2_front_Bit_sparse:\n",
    "            key += '-sparse'\n",
    "        if row.job_algo_AstarPa2_front_Bit_simd:\n",
    "            key += '-simd'\n",
    "        if row.job_algo_AstarPa2_sparsehcalls:\n",
    "            key += '-h'\n",
    "        return key\n",
    "    return 'unknown'\n",
    "\n",
    "# Returns display name, color, and style for an algorithm\n",
    "def algorithm_display(row, split):\n",
    "    (c, l, n) = algorithm_styles[row['algo_key']]\n",
    "    if 'r' in split:\n",
    "        if row.r:\n",
    "            n += f' (r={row.r})'\n",
    "    return (c, l, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e17c2ce-b24b-4a8b-bce4-46f050d1f99b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def read_results(path):\n",
    "    # - Read a json file\n",
    "    # - Rename json fields from a_b to a-b\n",
    "    # - Flatten into dataframe\n",
    "    # - Flatten algorithm params into a few fields:\n",
    "    #   - algo_name: the type of algorithm\n",
    "    #   - algo_full: the json-string of algorithm parameters\n",
    "    # - Rename and compute some common columns:\n",
    "    #   - error-rate\n",
    "    #   - length\n",
    "    #   - s_per_pair\n",
    "    #   - p_correct\n",
    "    \n",
    "    json_path = Path(path)\n",
    "    data = json.loads(json_path.read_text())\n",
    "    \n",
    "    # Remove underscores from all keys\n",
    "    def remove_underscores(o):\n",
    "        if isinstance(o, list):\n",
    "            return [remove_underscores(v) for v in o]\n",
    "        if isinstance(o, dict):\n",
    "            return {k.replace('_', ''): remove_underscores(v) for k, v in o.items()}\n",
    "        return o\n",
    "    \n",
    "    data = remove_underscores(data)\n",
    "\n",
    "    # Clean up algo columns\n",
    "    for x in data:\n",
    "        name = list(x['job']['algo'].keys())[0]\n",
    "        obj = x['job']['algo']\n",
    "        obj['name'] = name\n",
    "        x['algo_name'] = name\n",
    "        x['algo_full'] = json.dumps(obj)\n",
    "        #del x['job']['algo']\n",
    "        if 'Ok' in x['output']:\n",
    "            del x['output']['Ok']['costs']\n",
    "\n",
    "    # Flatten the js\n",
    "    df = pd.json_normalize(data, sep='_')\n",
    "    df['algo_key'] = df.apply(get_algorithm_key, axis=1)\n",
    "    df['algo_pretty'] = df['algo_key'].map(lambda key: algorithm_styles[key][2])\n",
    "    \n",
    "    # Convenience renaming\n",
    "    df = df.rename({'job_dataset_Generated_length': 'length',\n",
    "                    'job_dataset_Generated_errorrate': 'errorrate',\n",
    "                    'job_timelimit': 'timelimit',\n",
    "                    'output_Ok_pcorrect': 'pcorrect',\n",
    "                    'output_Ok_measured_runtime': 'runtime',\n",
    "                    'output_Ok_measured_memory': 'memory',\n",
    "                    'stats_divergence_mean': 'divergence',\n",
    "                    'job_algo_AstarPa_diagonaltransition': 'dt',\n",
    "                    'job_algo_AstarPa_heuristic_prune': 'prune',\n",
    "                    'job_algo_AstarPa_heuristic_r': 'r',\n",
    "                    #'job_algo_AstarPa2_heuristic_r': 'r',\n",
    "                   }, axis='columns')\n",
    "    if 'r' not in df.columns:\n",
    "        df['r'] = 1\n",
    "    \n",
    "    # Order rows\n",
    "    df['algo_ord'] = df['algo_key'].map(lambda key: algorithm_order.index(key))\n",
    "    df.sort_values(by='algo_ord', inplace=True, kind = 'stable')\n",
    "    if 'length' in df.columns:\n",
    "        df.sort_values(by='length', inplace=True, kind = 'stable')\n",
    "    if 'errorrate' in df.columns:\n",
    "        df.sort_values(by='errorrate', inplace=True, kind = 'stable')\n",
    "    # Order by dataset\n",
    "    if 'job_dataset_File' in df.columns and df.job_dataset_File.notna().all():\n",
    "        df['dataset'] = df['job_dataset_File'].map(lambda f: Path(f).parent.name)\n",
    "        df['dataset_ord'] = df['dataset'].map(dataset_key)\n",
    "        df.sort_values(by='dataset_ord', inplace=True, kind = 'stable')\n",
    "    \n",
    "    # Computed columns\n",
    "    df['costmodel'] = df.apply(lambda row: (row['job_costs_sub'], row['job_costs_open'], row['job_costs_extend']), axis=1)\n",
    "    df['s_per_pair'] = df['runtime'] / df['stats_seqpairs']\n",
    "    df['timelimit_per_pair'] = df['timelimit'] / df['stats_seqpairs']\n",
    "    if 'length' in df.columns and 'output_Ok_stats_expanded' in df.columns:\n",
    "        df['band'] = df['output_Ok_stats_expanded'] / (df['stats_seqpairs']* df['length'])\n",
    "\n",
    "    def runtime_capped(row):\n",
    "        if not math.isnan(row['runtime']):\n",
    "            return row['runtime']\n",
    "        if row['output_Err'] == 'Timeout':\n",
    "            return row['timelimit']\n",
    "        return row['timelimit']*1.1\n",
    "    df['runtime_capped'] = df.apply(runtime_capped, axis = 1)\n",
    "    df['s_per_pair_capped'] = df['runtime_capped'] / df['stats_seqpairs']\n",
    "    \n",
    "    df['editdistance'] = df['stats_insertions'] + df['stats_deletions'] + df['stats_substitutions']\n",
    "    \n",
    "    # Some specific fixes\n",
    "    df = df.fillna({'r': 0}, downcast='infer')\n",
    "    \n",
    "    # Remove unsupported algos\n",
    "    if 'output_Err' in df.columns:\n",
    "        df = df[df.output_Err != 'Unsupported']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acf3277-8017-41a0-a644-17e274eb0c96",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## The one plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd32cae0-663f-47fa-a914-919244118597",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot(df,\n",
    "         name='',\n",
    "         file=None,\n",
    "         x='length',\n",
    "         y='s_per_pair',\n",
    "         # Column to use for hue and style.\n",
    "         # Always change both at the same time!\n",
    "         hue='algo_key',\n",
    "         style='r',\n",
    "         # column to use for marker size\n",
    "         size=None,\n",
    "         # Logarithmic axes by default\n",
    "         xlog=True,\n",
    "         xlim=(0, None),\n",
    "         ylog=True,\n",
    "         ylim=None,\n",
    "         # alph\n",
    "         alpha=1.0,\n",
    "         # Use line instead of scatter plot?\n",
    "         connect=False,\n",
    "         # Draw a cone from the given filter and x\n",
    "         cone=None,\n",
    "         cone_x=3*10**4,\n",
    "         fit=False,\n",
    "         line_labels=False,\n",
    "         categorical=False,\n",
    "         ax=None,\n",
    "         width=None,\n",
    "         height=None,\n",
    "         png=False,\n",
    "         mp=None\n",
    "        ):\n",
    "    \n",
    "    if df[y].isna().all():\n",
    "        print(f\"All values of {y} are nan.\")\n",
    "        return\n",
    "    \n",
    "    df = df[df[y].notnull()]\n",
    "    assert not df.empty\n",
    "    \n",
    "    # We group data by this set of keys.\n",
    "    split = [hue, style]\n",
    "    \n",
    "    # Remove 'r' from the split if not both r=1 and r=2 are present,\n",
    "    # to prevent redundant (r=1) in plots.\n",
    "    if 'r' in split and 'r' in df.columns:\n",
    "        if not (1 in df.r.values and 2 in df.r.values):\n",
    "            split.remove('r')\n",
    "    \n",
    "    # Group the data into datapoints per line\n",
    "    groups = df.groupby(split, sort=False)\n",
    "    \n",
    "    # Not sure if needed actually.\n",
    "    sns.reset_defaults()\n",
    "    sns.set_context(None) # 'paper', 'notebook'\n",
    "    \n",
    "    # Set up the figure if not provided.\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "        width = width or 3\n",
    "        height = height or 2\n",
    "        fig.set_size_inches(width, height, forward=True)\n",
    "        hasax = False\n",
    "    else:\n",
    "        hasax = True\n",
    "\n",
    "    \n",
    "    # Set log scales\n",
    "    ax.set(xscale='log' if xlog else 'linear', yscale='log' if ylog else 'linear')\n",
    "    \n",
    "    # limit number of ticks\n",
    "    if ylog:\n",
    "        ax.locator_params(axis='y', numticks=6)\n",
    "        ax.yaxis.set_minor_formatter(plt.NullFormatter())\n",
    "    else:\n",
    "        ax.locator_params(axis='y', nbins=6)\n",
    "\n",
    "    if xlog:\n",
    "        ax.locator_params(axis='x', numticks=6)\n",
    "        ax.xaxis.set_minor_formatter(plt.NullFormatter())\n",
    "    else:\n",
    "        ax.locator_params(axis='x', nbins=5)\n",
    "    \n",
    "    \n",
    "    # PLOTTING\n",
    "    \n",
    "    if not categorical:\n",
    "        # Show a scatterplot of points.\n",
    "        # Each group is plotted separately for more control over its style.\n",
    "        for k, group in groups:\n",
    "            first_row = group.iloc[0]\n",
    "            color, linestyle, grouplabel = algorithm_display(first_row, split)\n",
    "\n",
    "            ax.plot(x,\n",
    "                    y,\n",
    "                    data=group.sort_values(by=x),\n",
    "                    color=color,\n",
    "                    linestyle=linestyle if connect else 'None',\n",
    "                    marker='o',\n",
    "                    alpha=alpha,\n",
    "                    dash_capstyle = 'round',\n",
    "                    label=grouplabel,\n",
    "                    zorder=2,\n",
    "                    markersize=markersize,\n",
    "                    linewidth=linewidth\n",
    "                   )\n",
    "    if categorical:\n",
    "        # Overlay a boxplot and swarmplot on top of each other\n",
    "        sns.swarmplot(data=df,\n",
    "                        x=x,\n",
    "                        y=y,\n",
    "                        hue=hue,\n",
    "                        palette=palette,\n",
    "                        ax=ax,\n",
    "                        size=3,\n",
    "                        linewidth=0,\n",
    "                        edgecolor='gray',\n",
    "                        zorder=0.5,\n",
    "                        dodge=False,\n",
    "        )\n",
    "        sns.boxplot(data=df,\n",
    "                    x=x,\n",
    "                    y=y,\n",
    "                    ax=ax,\n",
    "                    linewidth=linewidth,\n",
    "                    whis=0,\n",
    "                    showcaps=False,\n",
    "                    showfliers=False,\n",
    "                    boxprops={'facecolor':'None'},\n",
    "                    whiskerprops={'linewidth':0},\n",
    "                    showmeans=True,\n",
    "                    meanprops={\"marker\":\"o\",\n",
    "                               \"markerfacecolor\":\"white\", \n",
    "                               \"markeredgecolor\":\"red\",\n",
    "                               \"markersize\":\"7\"}\n",
    "                    )\n",
    "    \n",
    "    # TEXT\n",
    "    \n",
    "    # Title\n",
    "    if name:\n",
    "        ax.set_title(name, y=1.05)\n",
    "    \n",
    "    # Remove legend\n",
    "    ax.legend().remove()\n",
    "    \n",
    "    # BACKGROUND\n",
    "    ax.set_facecolor(\"#F8F8F8\")\n",
    "    ax.set_axisbelow(True) \n",
    "    ax.grid(False)\n",
    "    if categorical:\n",
    "        ax.tick_params(axis=\"y\", which=\"both\", right=True)\n",
    "        ax.grid(True, axis=\"y\", which=\"major\", color=\"black\", alpha=.5, zorder=0, lw=0.5)\n",
    "        ax.grid(True, axis=\"y\", which=\"minor\", color=\"black\", alpha=.1, zorder=0, lw=0.5)\n",
    "    else:\n",
    "        ax.grid(True, axis=\"y\", which=\"major\", color=\"white\", alpha=1, zorder=0)\n",
    "    \n",
    "    \n",
    "    # AXES\n",
    "    \n",
    "    # Labels\n",
    "    ax.set_xlabel(column_display_name(x))  # weight='bold',\n",
    "    ax.set_ylabel(column_display_name(y), rotation=0, ha=\"left\")\n",
    "    ax.yaxis.set_label_coords(-0.5/width if width else -0.1, 1.00)\n",
    "    \n",
    "    # Limits\n",
    "    x_margin = 1.5\n",
    "    y_margin = 1.5\n",
    "    if xlog:\n",
    "        #xs = df[df[x] > 0][x]\n",
    "        ax.set_xlim(df[x].min() / x_margin, df[x].max() * x_margin)\n",
    "\n",
    "    if ylog:\n",
    "        ax.set_ylim(df[y].min() / y_margin, df[y].max() * y_margin)\n",
    "    \n",
    "    # Start linear scales at 0.\n",
    "    if not xlog and not categorical and x != 'job_costs_open':\n",
    "        ax.set(xlim=xlim)\n",
    "    if not ylog:\n",
    "        ax.set(ylim=(0,None))\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim[0], ylim[1])\n",
    " \n",
    "    \n",
    "    # Show bottom spine, and left spine when xlog=false\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(True)\n",
    "    ax.spines['left'].set_visible(not xlog and not categorical)\n",
    "    \n",
    "    # Format % scales.\n",
    "    if x in ['errorrate', 'divergence']:\n",
    "        ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0, decimals=0))\n",
    "    \n",
    "    # Show major ticks\n",
    "    ax.tick_params(\n",
    "        axis=\"both\",\n",
    "        which=\"major\",\n",
    "        bottom=True,\n",
    "        top=False,\n",
    "        left=True,\n",
    "        right=False,\n",
    "    )\n",
    "    # No minor ticks\n",
    "    ax.tick_params(\n",
    "        axis=\"both\",\n",
    "        which=\"minor\",\n",
    "        bottom=False,\n",
    "        top=False,\n",
    "        left=False,\n",
    "        right=False,\n",
    "        labelbottom=False,  # labels along the bottom edge are off\n",
    "    )\n",
    "    # Do show minor ticks for small log ranges\n",
    "    if ylog:\n",
    "         ax.tick_params(axis=\"y\", which=\"minor\", left=True)\n",
    "    \n",
    "    \n",
    "    # CONE\n",
    "    # Fills the region between x**1 and x**2\n",
    "    if cone:\n",
    "        x0 = cone_x\n",
    "        x_max = x_margin * df[x].max()\n",
    "        x_range = (x0, x_max)\n",
    "        \n",
    "        y0 = df[cone(df) & (df[x] == cone_x)][y].max()\n",
    "        y_lin = (y0, y0 * (x_max / x0) ** 1)\n",
    "        y_quad = (y0, y0 * (x_max / x0) ** 2)\n",
    "        ax.fill_between(x_range, y_lin, y_quad, color=\"grey\", alpha=0.15, zorder=0.4)\n",
    "        \n",
    "    # TIME LIMIT\n",
    "    if y=='runtime_capped' or (y=='s_per_pair_capped' and x != 'length'):\n",
    "        timelimit = df.timelimit_per_pair.iloc[0]\n",
    "        # assert df[df.runtime.isna()].timelimit_per_pair.eq(timelimit).all()\n",
    "        \n",
    "        # Draw a red line at the timelimit.\n",
    "        ax.axhline(y=timelimit, color=\"red\", linestyle=\"-\", alpha=1, linewidth=0.5)\n",
    "        \n",
    "        # Modify/add the timelimit ticklabel with TL=\n",
    "        if False:\n",
    "            ylabels = [x for x in ax.get_yticklabels()]\n",
    "            found = False\n",
    "            for i, l in enumerate(ylabels):\n",
    "                if l.get_position()[1] == timelimit:\n",
    "                    ylabels[i] = \"TL=\" + ylabels[i].get_text()\n",
    "                    found = True\n",
    "            if found:\n",
    "                ax.set_yticklabels(ylabels)\n",
    "            else:\n",
    "                yticks = list(ax.get_yticks())\n",
    "                ylabels = list(ax.get_yticklabels())\n",
    "                yticks.append(timelimit)\n",
    "                ylabels.append(\"TLE\")\n",
    "                ax.set_yticks(yticks)\n",
    "                try:\n",
    "                    ax.set_yticklabels(ylabels)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                finally:\n",
    "                    pass\n",
    "            \n",
    "    # POLY FIT\n",
    "\n",
    "    def angle(slope):\n",
    "        x_min, x_max = ax.get_xlim()\n",
    "        y_min, y_max = ax.get_ylim()\n",
    "        bbox = ax.get_window_extent()\n",
    "        x_sz = bbox.width\n",
    "        y_sz = bbox.height\n",
    "        x_factor = x_sz / (np.log10(x_max) - np.log10(x_min) if xlog else x_max - x_min)\n",
    "        y_factor = y_sz / (np.log10(y_max) - np.log10(y_min) if ylog else y_max - y_min) \n",
    "        slope = slope * y_factor / x_factor\n",
    "        return math.atan(slope)*180/math.pi\n",
    "    \n",
    "    if fit:\n",
    "        assert x=='length' and xlog and ylog, \"Polynomial fits only work in log-log plots with x=length\"\n",
    "        for k, group in groups:\n",
    "            first_row = group.iloc[0]\n",
    "            color, linestyle, grouplabel = algorithm_display(first_row, split)\n",
    "            grouplabel = grouplabel.replace('\\n', ' ')\n",
    "            fit_label = grouplabel\n",
    "            \n",
    "            filtered = group[group.runtime.notnull()]\n",
    "            ps = filtered[[x,y]].dropna()\n",
    "            xmin, xmax = filtered[x].min(), filtered[x].max()\n",
    "            if len(ps) > 1:\n",
    "                fit = np.polyfit(np.log(ps[x]), np.log(ps[y]), 1)\n",
    "                f = lambda x: x**fit[0] * np.exp(fit[1])\n",
    "                # Extra {{ and }} are for the math-mode superscript\n",
    "                fit_label = f\"{grouplabel} $\\sim n^{{{fit[0]:0.2f}}}$\"\n",
    "\n",
    "                ymin, ymax = f(xmin), f(xmax)\n",
    "                # line from xmin to xmax (use plt.axline for infinite line)\n",
    "                ax.plot([xmin, xmax], [ymin, ymax], color=color, linestyle=linestyle, alpha=1, dash_capstyle = 'round', zorder=2, linewidth=linewidth)\n",
    "                #print(f'Exponent for {k}: {fit[0]:0.2f}')\n",
    "\n",
    "            ax.text(\n",
    "                xmax,\n",
    "                min(ymax, ax.get_ylim()[1]),\n",
    "                fit_label,\n",
    "                color=color,\n",
    "                ha=\"right\",\n",
    "                va=\"bottom\",\n",
    "                size=labelsize,\n",
    "                alpha=1,\n",
    "                rotation=angle(fit[0]),\n",
    "                rotation_mode='anchor',\n",
    "            )\n",
    "    if line_labels:\n",
    "        # If no legend and no fits are shown, show manual labels instead\n",
    "        for split_key, group in groups:\n",
    "            first_row = group.iloc[0]\n",
    "            color, linestyle, grouplabel = algorithm_display(first_row, split)\n",
    "\n",
    "            grouplabel = grouplabel.replace('\\n', ' ')\n",
    "\n",
    "            max_idx = group[x].idxmax()\n",
    "            label_x = group[x][max_idx]\n",
    "            label_y = min(group[y][max_idx], ax.get_ylim()[1])\n",
    "            key = split_key[0] if isinstance(split_key, tuple) else split_key\n",
    "            \n",
    "            by_x = group[x].argsort()\n",
    "            last = group.iloc[by_x.iloc[-1]]\n",
    "            before = group.iloc[by_x.iloc[-3]]\n",
    "            slope = (last[y] - before[y])/(last[x] - before[x])\n",
    "            ax.text(\n",
    "                label_x,\n",
    "                label_y,\n",
    "                grouplabel,\n",
    "                color=color,\n",
    "                ha=\"right\",\n",
    "                va=\"bottom\",\n",
    "                size=labelsize,\n",
    "                alpha=1,\n",
    "                rotation=angle(slope),\n",
    "                rotation_mode='anchor',\n",
    "            )\n",
    "\n",
    "    if not hasax:\n",
    "        if file:\n",
    "            plt.savefig(f\"plots/{file}.svg\", dpi=300, bbox_inches='tight')\n",
    "            if png:\n",
    "                plt.savefig(f\"plots/{file}.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508cf978-5902-4a69-8bb9-a728e3a06a74",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Scaling with LENGTH\n",
    "\n",
    "# df = read_results('results/scaling-n.json')\n",
    "\n",
    "# cone = lambda df: (df['algo_key'] == 'gcsh-dt') & (df['r'] == (1 if e <= 0.05 else 2))\n",
    "# for e, g in df.groupby('errorrate'):\n",
    "#     plot(g, file=f'scaling_n_e{e}', x='length', y='s_per_pair', fit=True, cone=cone, cone_x = 10**4, width=4.4, height=3)\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbcbbdd-50f0-449d-9306-52d390b5c427",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scaling with DIVERGENCE\n",
    "df = read_results(\"results/scaling-e.json\")\n",
    "plot(df, file=f'scaling_e', x='divergence', y='s_per_pair', size=None, xlog=False, ylog=False, connect=True, line_labels=True,\n",
    "     ylim=(0,0.28), width=4.4, height=3)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67455ed7-cbf1-4615-8590-40465e3110a1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Boxplots on real data\n",
    "def boxplot(path, w0, row=False, vlines=[], wr=None,wspace=0.15):\n",
    "    df = read_results(f\"results/{path}.json\")\n",
    "    ww=1\n",
    "    datasets = len(df.dataset.unique())\n",
    "    hh = (datasets+ww-1)//ww\n",
    "    if row:\n",
    "        ww,hh=hh,ww\n",
    "    w = ww*w0\n",
    "    h = 3.7 * hh\n",
    "    fig, axs = plt.subplots(hh, ww, figsize=(w, h), gridspec_kw={'width_ratios': wr})\n",
    "    if not isinstance(axs, np.ndarray):\n",
    "        axs = [axs]\n",
    "    if isinstance(axs[0], np.ndarray):\n",
    "        axs = [x for col in zip(*axs) for x in col]\n",
    "    for (k, g), ax in zip(df.groupby('dataset',sort=False),axs):\n",
    "        avg = g.stats_seqpairs.unique().max() > 1\n",
    "        plot(g, x='algo_pretty', y='s_per_pair_capped' if avg else 'runtime_capped',\n",
    "             xlog=False,\n",
    "             ylog=True,\n",
    "             ylim=None,\n",
    "             categorical=True,\n",
    "             ax=ax,\n",
    "             width=w,\n",
    "             )\n",
    "        ax.set_xlabel(dataset_pretty.get(k, k))\n",
    "        for x in vlines:\n",
    "            ax.axvline(x=x, color=\"black\", alpha=0.5, linewidth=0.5, zorder=0.1)\n",
    "    \n",
    "    fig.subplots_adjust(wspace=wspace, hspace=0.4)\n",
    "\n",
    "    plt.savefig(f\"plots/{path}.svg\", bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3f4b9d-5ab6-49b0-af48-f15d6bddbd28",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# REAL\n",
    "boxplot('real-incremental', 11, vlines=[1.5, 3.5, 11.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346bf045-f5d6-4fea-9076-f66fc9d23f19",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SUMMARY\n",
    "boxplot('real-summary', 3.5, row=True, wspace=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2643948-eb64-4c0a-a1d9-98f859f81178",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ABLATION\n",
    "boxplot('real-ablation', 6, wr=[12, 7, 7], row=True, vlines=[0.5], wspace=0.11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1e3b1d-71c5-4a34-bd1c-9d7dab6193c3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "boxplot('real-params', 6, wr=[15,10,10], row=True, vlines=[0.5], wspace=0.11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ecd4fd-1afe-45aa-a27b-820fc850143c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SCATTER PLOTS ON REAL DATA\n",
    "def scatterplot(path, w0, row=False, vlines=[], wr=None,wspace=0.15):\n",
    "    df = read_results(f\"results/{path}.json\")\n",
    "    ww=1\n",
    "    datasets = len(df.dataset.unique())\n",
    "    hh = (datasets+ww-1)//ww\n",
    "    if row:\n",
    "        ww,hh=hh,ww\n",
    "    w = ww*w0\n",
    "    h = 3.7 * hh\n",
    "    fig, axs = plt.subplots(hh, ww, figsize=(w, h), gridspec_kw={'width_ratios': wr})\n",
    "    if not isinstance(axs, np.ndarray):\n",
    "        axs = [axs]\n",
    "    if isinstance(axs[0], np.ndarray):\n",
    "        axs = [x for col in zip(*axs) for x in col]\n",
    "    for (k, g), ax in zip(df.groupby('dataset',sort=False),axs):\n",
    "        avg = g.stats_seqpairs.unique().max() > 1\n",
    "        plot(g,\n",
    "             x='divergence',\n",
    "             y='s_per_pair_capped' if avg else 'runtime_capped',\n",
    "             hue='algo_key',\n",
    "             xlog=False,\n",
    "             ylog=True,\n",
    "             ylim=None,\n",
    "             categorical=False,\n",
    "             ax=ax,\n",
    "             width=w,\n",
    "             xlim=None,\n",
    "             )\n",
    "        ax.set_xlabel(dataset_pretty.get(k, k))\n",
    "        for x in vlines:\n",
    "            ax.axvline(x=x, color=\"black\", alpha=0.5, linewidth=0.5, zorder=0.1)\n",
    "    \n",
    "    fig.subplots_adjust(wspace=wspace, hspace=0.4)\n",
    "\n",
    "    plt.savefig(f\"plots/{path}-scatter.svg\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "scatterplot('real-summary', 3.5, row=True, wspace=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61c110b-7dab-42a3-a70b-935a5411f6e5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TIMING\n",
    "df = read_results(\"results/real-timing.json\")\n",
    "time_labels = {\n",
    "    'precomp': 'Precomputation',\n",
    "    'jrange': 'Range to compute',\n",
    "    'fixedjrange': 'Range to reuse',\n",
    "    'compute': 'Computing blocks',\n",
    "    'pruning': 'Pruning matches',\n",
    "    'tracedt': 'DT trace',\n",
    "    'tracefill': 'Fill trace',\n",
    "    'rest': 'Overhead',\n",
    "}\n",
    "\n",
    "for c in df.columns:\n",
    "    prefix = 'output_Ok_stats_t'\n",
    "    if c.startswith(prefix):\n",
    "        name = c[len(prefix):]\n",
    "        label = time_labels.get(name, name)\n",
    "        df[label] = df[c] / df['stats_seqpairs']\n",
    "\n",
    "def rest(row):\n",
    "    t = row['s_per_pair']\n",
    "    for c in time_labels.values():\n",
    "        if c == 'Overhead': continue\n",
    "        t -= row[c]\n",
    "    return t\n",
    "\n",
    "df['Overhead'] = df.apply(rest, axis=1)\n",
    "\n",
    "datasets = len(df.dataset.unique())\n",
    "fig, axes = plt.subplots(nrows=1, ncols=datasets, figsize=(3.5*datasets, 3.7))\n",
    "fig.subplots_adjust(wspace=0.3)\n",
    "\n",
    "ymax = [0.69, 0.69, None, 0.00011, 0.00055, None]\n",
    "\n",
    "for i, ((k, g), ax, ymax) in enumerate(zip(df.groupby('dataset', sort=False), axes, ymax)):\n",
    "    df = g\n",
    "    df.sort_values(by='s_per_pair', inplace=True, kind = 'stable')\n",
    "    df.plot.bar(y = time_labels.values(), stacked=True, width=.9, zorder=2, ax=ax, color = sns.color_palette(), ylim=(0, ymax))\n",
    "    if df.stats_seqpairs.max() > 1:\n",
    "        label = 'Avg. runtime per alignment [s]'\n",
    "    else:\n",
    "        label = 'Runtime per alignment [s]'\n",
    "    ax.set_ylabel(label, rotation=0, ha=\"left\")\n",
    "    ax.set_xlabel(dataset_pretty[k])\n",
    "    if i > 0:\n",
    "        ax.legend().remove()\n",
    "    ax.tick_params(\n",
    "        bottom=False,\n",
    "    )\n",
    "    # ax.ticklabel_format(style='sci', axis='y', scilimits=(0,0),useOffset=False)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.locator_params(axis='y', nbins=2)\n",
    "    # ax.yaxis.set_major_formatter(mtick.LogFormatterSciNotation(labelOnlyBase=False, minor_thresholds=(2,2), linthresh=1))\n",
    "    ax.set_facecolor(\"#F8F8F8\")\n",
    "    ax.grid(False)\n",
    "    ax.grid(True, axis=\"y\", which=\"major\", color=\"w\")\n",
    "    ax.yaxis.set_label_coords(-0.15,1.0)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(True)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    \n",
    "plt.savefig(f\"plots/real-timing.svg\", bbox_inches='tight')    \n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ad176c-636f-4d9f-9f10-71bf3535df22",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO BAND???\n",
    "def band(path, w0, row=False, vlines=[], wr=None,wspace=0.15):\n",
    "    df = read_results(f\"results/{path}.json\")\n",
    "    df['band'] = df['output_Ok_stats_computedlanes'] / df['stats_seqpairs'] / df['stats_length_mean'] * df['job_algo_AstarPa2_blockwidth'] * 64\n",
    "    df['uniqueband'] = df['output_Ok_stats_uniquelanes'] / df['stats_seqpairs'] / df['stats_length_mean'] * df['job_algo_AstarPa2_blockwidth'] * 64\n",
    "    ww=1\n",
    "    datasets = len(df.dataset.unique())\n",
    "    hh = (datasets+ww-1)//ww\n",
    "    if row:\n",
    "        ww,hh=hh,ww\n",
    "    w = ww*w0\n",
    "    h = 3.7 * hh\n",
    "    fig, axs = plt.subplots(hh, ww, figsize=(w, h), gridspec_kw={'width_ratios': wr})\n",
    "    if not isinstance(axs, np.ndarray):\n",
    "        axs = [axs]\n",
    "    if isinstance(axs[0], np.ndarray):\n",
    "        axs = [x for col in zip(*axs) for x in col]\n",
    "    for (k, g), ax in zip(df.groupby('dataset',sort=False),axs):\n",
    "        avg = g.stats_seqpairs.unique().max() > 1\n",
    "        plot(g,\n",
    "             x='divergence',\n",
    "             y='band',\n",
    "             hue='algo_key',\n",
    "             xlog=False,\n",
    "             ylog=True,\n",
    "             ylim=None,\n",
    "             categorical=False,\n",
    "             ax=ax,\n",
    "             width=w,\n",
    "             xlim=None,\n",
    "             )\n",
    "        ax.set_xlabel(dataset_pretty.get(k, k))\n",
    "        for x in vlines:\n",
    "            ax.axvline(x=x, color=\"black\", alpha=0.5, linewidth=0.5, zorder=0.1)\n",
    "    \n",
    "    fig.subplots_adjust(wspace=wspace, hspace=0.4)\n",
    "\n",
    "    plt.savefig(f\"plots/{path}-band.svg\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "band('real-timing', 3.5, row=True, wspace=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7577594f-1994-4697-8bf8-50bc3354cfa9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MEMORY USAGE\n",
    "df = read_results(\"results/real-summary.json\")\n",
    "df.loc[df.algo_key == 'astarpa-r1', 'algo_key'] = 'astarpa'\n",
    "df = df[df.memory.notna()]\n",
    "df.memory = df.memory/1000000\n",
    "df['memory2'] = df.memory\n",
    "#df = df[df.algo_key.isin(['edlib', 'biwfa', 'gcsh-dt', 'astarnw', 'astarnw-sparse'])]\n",
    "table = df.pivot_table(index='algo_key', columns=['dataset'], values=['memory2', 'memory'], aggfunc={'memory2': np.median, 'memory': np.max}, sort=False).round(0)\n",
    "table =table.rename({'memory2': 'Median', 'memory': 'Max'}, axis='columns')\n",
    "table = table.swaplevel(axis=1)\n",
    "def key_fn(keys):\n",
    "    return [dataset_key(key)[0] for key in keys]\n",
    "table.sort_index(axis=1, level=0, inplace=True, sort_remaining=False, key=key_fn)\n",
    "# Pretty column names\n",
    "table = table.rename(axis=1, level=0, mapper=lambda c: dataset_pretty[c])\n",
    "table = table.rename(axis=0, mapper=lambda a: algorithm_styles[a][2].replace('\\n', ' '))\n",
    "display(table)\n",
    "import tabulate\n",
    "headers = [' '.join(c) for c in table.columns]\n",
    "print(tabulate.tabulate(table, headers=headers, tablefmt='orgtbl'))\n",
    "#print(table.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e295e822-f319-41fe-b21b-1a87c794c43e",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Sanity check: CPU frequency\n",
    "Make sure that the CPU frequency is consistent over all experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67938fe-6d27-4945-b503-07924df89577",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = read_results(\"results/real.json\")\n",
    "df = df.rename({'output_Ok_measured_cpufreqstart': 'freqstart','output_Ok_measured_cpufreqend': 'freqend'}, axis='columns')\n",
    "for c in ['freqstart', 'freqend']:\n",
    "    print(df[c].min(), df[c].max())\n",
    "    assert df[c].min() > 3250\n",
    "    assert df[c].max() < 3350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0cd5ab-bfa7-4189-b4f4-cffbad428969",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%history -g -f filename"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (ipykernel)",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "name": "evals.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
